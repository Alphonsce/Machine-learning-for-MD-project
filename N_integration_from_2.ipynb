{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from numba import njit, jit\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "\n",
    "from utility_funcs import *\n",
    "from LJ_modeling_realization.includes.constants import *\n",
    "\n",
    "import dill\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, ConstantKernel, RBF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = CFG.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = float(input(\"integrated dt:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"gpr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnModel:\n",
    "    def __init__(self, model):\n",
    "        '''\n",
    "        model - sklearn model\n",
    "        '''\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = f'./trained_models/{model_type}_2_movements_K3.pickle'\n",
    "model_vel_file_path = f'./trained_models/{model_type}_2_velocities_K3.pickle'\n",
    "\n",
    "# Сетка предсказания сжатые будет выдавать и их надо будет возвращать к обычному скейлу\n",
    "descaler_path = f'./trained_models/descaler_{CFG.N}_K{CFG.K}.pickle'\n",
    "descaler_vel_path = f'./trained_models/descaler_vel_{CFG.N}_K{CFG.K}.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_file_path, 'rb') as handle:\n",
    "    model = dill.load(handle)\n",
    "\n",
    "with open(model_vel_file_path, 'rb') as handle:\n",
    "    model_vel = dill.load(handle)\n",
    "\n",
    "if model_type == \"gpr\":\n",
    "    descaler = Descaler(1, 0)\n",
    "    descaler_vel = Descaler(1, 0)\n",
    "    model = SklearnModel(model)\n",
    "    model_vel = SklearnModel(model_vel)\n",
    "else:\n",
    "    with open(descaler_path, 'rb') as handle:\n",
    "        descaler = dill.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_row_to_state(coords_path, vels_path, row_number=0):\n",
    "    '''\n",
    "    This function will be mostly used to start integration and create header for csv to write into\n",
    "    '''\n",
    "\n",
    "    row_coords = np.array(pd.read_csv(\n",
    "        coords_path\n",
    "    ).iloc[row_number, :][1:]).reshape(CFG.N, 3)\n",
    "\n",
    "    row_vels = np.array(pd.read_csv(\n",
    "        vels_path\n",
    "    ).iloc[0, :][1:]).reshape(CFG.N, 3)\n",
    "    \n",
    "    state = {i: [row_coords[i], row_vels[i]] for i in range(CFG.N)}\n",
    "\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = csv_row_to_state(\n",
    "    f'./LJ_modeling_realization/folded_coords{CFG.N}.csv',\n",
    "    f'./LJ_modeling_realization/velocities{CFG.N}.csv',\n",
    "\n",
    "    row_number=-1   # НАЧИНАЕМ ПРЕДСКАЗЫВАТЬ С КОНЦА ИЗВЕСТНОЙ ТРАЕКТОРИИ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(n_state, atom_numb):\n",
    "    '''\n",
    "    Возвращает все расстояния от данного атома\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def get_closest_atom(state, atom_number):\n",
    "    other_atom_numbers = [i for i in range(CFG.N) if i != atom_number]\n",
    "    # print(other_atom_numbers)\n",
    "    Rel_matrix = np.zeros([CFG.N - 1, 3])\n",
    "\n",
    "    for i, other_numb in enumerate(other_atom_numbers):\n",
    "        Rel_matrix[i] = state[atom_number][0] - state[other_numb][0]\n",
    "\n",
    "    # Getting the closest atom to atom_number:\n",
    "    dists = norm(Rel_matrix, axis=1)\n",
    "\n",
    "    closest_num = np.argmin(dists)\n",
    "\n",
    "    closest_num += int(closest_num >= atom_number)   # Тут же пропущен индекс текущего атома - и надо сдвинуть типо\n",
    "\n",
    "    return closest_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_closest_atom(n_state, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ошибка в функции сверху ща: оно индекс не тот возвращает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_positions(state, atom_number):\n",
    "    '''\n",
    "    This function processes one row of csv into something that we can work with\n",
    "\n",
    "    Returns np.array matrix that consists of relative positions vectors for passed atom_number to every other atom\n",
    "    and then we can chose only closest N_neighbours in the next functions\n",
    "    \n",
    "    row: df.iloc[row] - typeof(row): pd.Series\n",
    "    \n",
    "    returns: Rel_matrix, f_vec\n",
    "    '''\n",
    "\n",
    "    other_atom_numbers = [i for i in range(2) if i != atom_number]\n",
    "    Rel_matrix = np.zeros([len(other_atom_numbers), 3])\n",
    "\n",
    "    for i, other_numb in enumerate(other_atom_numbers):\n",
    "        Rel_matrix[i] = state[atom_number][0] - state[other_numb][0]\n",
    "\n",
    "    return np.array(Rel_matrix)\n",
    "\n",
    "def create_V_i(i, normalized_m, norms, r_cut=CFG.r_cut, p=CFG.p):\n",
    "    '''\n",
    "    normalized_m: matrix of relative distances, where rows - normalized vectors\n",
    "    i: i-th component of r_cut and p, i in range 1..K (or in 0..K-1 in code)\n",
    "    '''\n",
    "    transf_vecs = make_matrix_transformed(normalized_m, norms[:, np.newaxis], r_cut[i], p[i])\n",
    "\n",
    "    return np.sum(transf_vecs, axis=0)\n",
    "\n",
    "# @njit(parallel=True)\n",
    "def create_V(normalized_m, norms, K=CFG.K):\n",
    "    '''\n",
    "    creates V\n",
    "    '''\n",
    "    V = []\n",
    "    for i in range(K):\n",
    "        V.append(\n",
    "            create_V_i(i, normalized_m, norms)\n",
    "        )\n",
    "\n",
    "    return np.stack(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force(r):\n",
    "    '''\n",
    "    r is a vector from one particle to another\n",
    "    '''\n",
    "\n",
    "    d = norm(r)\n",
    "\n",
    "    f = 4 * (12 * pow(d, -13) - 6 * pow(d, -7)) * (r / d)\n",
    "\n",
    "    # f = -10 * r\n",
    "\n",
    "    return f\n",
    "\n",
    "# @njit(\n",
    "#     parallel=True,\n",
    "#     fastmath=True\n",
    "#     )\n",
    "def _calculate_matrix_for_atom(relative_distances, rel_vel, r_cut=CFG.r_cut, p=CFG.p, N_neig=CFG.N_neig, K=CFG.K, use_orthogonal=False, use_A_t=True):\n",
    "    '''\n",
    "\n",
    "    relative_distances: np.array matrix of relative distance vectors\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Only closest N_neig are counting:\n",
    "    indexlist = np.argsort(norm(relative_distances, axis=1))\n",
    "\n",
    "    relative_distances = relative_distances[indexlist[len(relative_distances) - N_neig:]]\n",
    "\n",
    "    norms = norm(relative_distances, axis=-1)\n",
    "\n",
    "    normalized_rel_distances = relative_distances / norms[:, np.newaxis]\n",
    "\n",
    "    # ------СТАНДАРТНЫЙ РЕЖИМ:-------------------\n",
    "    # V = create_V(normalized_rel_distances, norms)\n",
    "\n",
    "\n",
    "    # if use_orthogonal and CFG.K == 3:\n",
    "    #     diagonal_V_matr = [[0] * CFG.K for i in range(K)]\n",
    "    #     for i in range(K):\n",
    "    #         diagonal_V_matr[i][i] = V[i][i]\n",
    "    #     V = np.array(\n",
    "    #         diagonal_V_matr\n",
    "    #     )\n",
    "    # ----------------ДЛЯ 2 ЧАСТИЦ РЕЖИМ:----------------------------\n",
    "\n",
    "    cross_vec = np.cross(relative_distances.squeeze(), rel_vel)\n",
    "    cross_vec = cross_vec / norm(cross_vec)\n",
    "\n",
    "    r = relative_distances.squeeze()\n",
    "\n",
    "    V = np.vstack(\n",
    "        [r,\n",
    "        force(r),\n",
    "        rel_vel\n",
    "        # np.cross(relative_distances.squeeze(), rel_vel)\n",
    "        ]\n",
    "    )\n",
    "    # print(relative_distances.squeeze(), rel_vel, np.cross(relative_distances, rel_vel))\n",
    "\n",
    "    A = V / norm(V, axis=-1)[:, np.newaxis]\n",
    "\n",
    "    # print(V)\n",
    "    # print(get_pinv(A))\n",
    "\n",
    "    if use_A_t:\n",
    "        X = V @ A.T\n",
    "    else:\n",
    "        X = V\n",
    "\n",
    "    return X, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def get_pinv(A):\n",
    "    return np.linalg.pinv(A)\n",
    "\n",
    "def get_matrix_for_atom(state, atom_number, N_neig=CFG.N_neig, use_orthogonal=True, use_A_t=True):\n",
    "    '''\n",
    "\n",
    "    This function will create X matrix for passed atom with\n",
    "    arrays of r_cut and p of length k\n",
    "\n",
    "    It is a wrapper for _get_relative_positions and _calculate_matrix_for_atom, so I can speed up matrix calculations\n",
    "    with numba for _calculate_matrix_for_atom\n",
    "\n",
    "    atom_number: a number of atom that we are passing\n",
    "    row: one row from df_with_coords, i.e. df.iloc[index_of_row]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # creating row of relative coordinates for concrete atom:\n",
    "    relative_distances = _get_relative_positions(state=state, atom_number=atom_number)\n",
    "\n",
    "    vel0 = state[0][1]\n",
    "    vel1 = state[1][1]\n",
    "\n",
    "    if atom_number == 0:\n",
    "        rel_vel = vel0 - vel1\n",
    "    else:\n",
    "        rel_vel = vel1 - vel0\n",
    "\n",
    "    X, A = _calculate_matrix_for_atom(relative_distances=relative_distances, rel_vel=rel_vel, N_neig=N_neig, use_orthogonal=use_orthogonal, use_A_t=use_A_t)\n",
    "\n",
    "    flat_X = np.concatenate([X.flatten(), state[atom_number][1]])\n",
    "\n",
    "    # print(\n",
    "    #     state\n",
    "    # )\n",
    "    \n",
    "    return flat_X, get_pinv(A)\n",
    "\n",
    "# %timeit get_matrix_for_atom(row=df.iloc[0], atom_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_naming_coords = []\n",
    "for i in range(CFG.N):\n",
    "    csv_naming_coords.extend([str(i) + \"x\", str(i) + \"y\", str(i) + \"z\"])\n",
    "result_coords_csv = \"./integration_res/result_coords_n_from_2.csv\"\n",
    "\n",
    "csv_naming_vels = []\n",
    "for i in range(CFG.N):\n",
    "    csv_naming_vels.extend([str(i) + \"vx\", str(i) + \"vy\", str(i) + \"vz\"])\n",
    "result_vels_csv = \"./integration_res/result_vels_n_from_2.csv\"\n",
    "\n",
    "\n",
    "def fill_csv(state, path, mode=\"coords\"):\n",
    "    '''\n",
    "    fills csv after current step\n",
    "    '''\n",
    "    s = ''\n",
    "    if mode == \"coords\":\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = 1\n",
    "    with open(path, \"a\") as f:\n",
    "        for atom_numb in range(CFG.N):\n",
    "            s += ',' + \",\".join(list(state[atom_numb][idx].astype(str)))\n",
    "        f.write(s[1:] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_step(n_state):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.6166295 , 0.42700003, 3.75230512]),\n",
       " array([2.14348987, 0.4460663 , 0.8382205 ])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_state[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Короче: перемещения надо брать из unfolded координат, матрицы признаков надо брать из folded координат, а мб я и не прав**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАПУСКАЮ ЦИКЛ, СЧИТАЮ ВСЕ РАССТОЯНИЯ, ЕСЛИ ОНО МИНИМАЛЬНОЕ - СТРОЮ state для текущий частицы с этой частицей - делаю предсказание для этой частицы, но пока не сдвигаю, так делаю для всех частиц и затем сдвигаю\n",
    "\n",
    "def make_predictions(n_state, model):\n",
    "    Xs = []\n",
    "    pinv_As = []\n",
    "    for atom_num in range(N):\n",
    "        state_2p = {}\n",
    "        other_atom_for_2p_state = get_closest_atom(n_state, atom_num)\n",
    "        # print(other_atom_for_2p_state)\n",
    "        state_2p = {0: n_state[atom_num], 1: n_state[other_atom_for_2p_state]}\n",
    "        # print(state_2p)\n",
    "        #\n",
    "        X, pinv_A = get_matrix_for_atom(state=state_2p, atom_number=0)  # в текущем стейте все время 0 атом - для которого предсказывать будем\n",
    "        Xs.append(X)\n",
    "        pinv_As.append(pinv_A)\n",
    "\n",
    "\n",
    "    # print(Xs)\n",
    "\n",
    "    Xs = np.array(Xs, dtype=np.float) if model_type != \"network\" else torch.tensor(np.array(Xs), dtype=torch.float)\n",
    "\n",
    "    pinv_As = np.array(pinv_As)\n",
    "    preds = descaler(model(Xs))\n",
    "\n",
    "    return [pinv_As[i] @ preds[i] for i in range(CFG.N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.86239076e-06, 1.50071894e-06, 1.15705657e-06]),\n",
       " array([-1.17380898e-10, -3.29429494e-10, -2.84651245e-10]),\n",
       " array([0., 0., 0.]),\n",
       " array([ 1.97696040e-106, -7.58777453e-107, -1.74887298e-107]),\n",
       " array([-8.78732575e-06, -1.04163483e-06, -2.06096658e-05]),\n",
       " array([ 6.49669253e-10, -2.59822511e-08,  7.80881698e-09]),\n",
       " array([-1.29939860e-106,  4.93421403e-107,  1.16956378e-107]),\n",
       " array([-1.33739126e-06, -4.16826726e-06,  5.01518250e-06]),\n",
       " array([-2.73088983e-08,  9.75004738e-08,  1.29814180e-07]),\n",
       " array([1.96315032e-07, 1.83714375e-07, 3.02853670e-07]),\n",
       " array([8.36725897e-07, 3.30492620e-06, 2.47271755e-06]),\n",
       " array([-4.11103109e-07, -1.92097237e-06, -1.45018881e-06]),\n",
       " array([ 5.72599184e-06,  5.88849505e-07, -6.96919976e-06]),\n",
       " array([-7.80543763e-05, -3.00748432e-05,  8.55637713e-05]),\n",
       " array([-4.64287547e-12,  4.37750356e-12,  8.59524889e-11]),\n",
       " array([ 2.76370072e-06, -2.08151530e-06, -1.56907245e-06]),\n",
       " array([-1.18380376e-17,  4.42647166e-20,  2.35743974e-17]),\n",
       " array([-7.20096828e-06,  2.81383130e-05, -9.28160410e-06]),\n",
       " array([-2.03526630e-07,  2.48774562e-07,  3.57589646e-08]),\n",
       " array([1.33287877e-05, 1.16045504e-06, 1.45295684e-05]),\n",
       " array([-2.78040359e-05,  3.04344773e-05, -2.20547665e-05]),\n",
       " array([3.12943463e-11, 2.04615483e-13, 1.81363542e-11]),\n",
       " array([-4.46305286e-05, -5.43195584e-06,  1.47546888e-06]),\n",
       " array([ 7.13772817e-05, -9.81348035e-05,  6.30268505e-05]),\n",
       " array([0., 0., 0.]),\n",
       " array([-3.34703231e-05,  4.35961315e-05,  2.66384247e-05]),\n",
       " array([ 1.64930597e-05, -6.12544614e-05,  7.18167411e-07]),\n",
       " array([ 7.90416471e-06,  7.92826945e-06, -7.01100093e-06]),\n",
       " array([-2.19511113e-06, -3.59678179e-07,  1.92566158e-06]),\n",
       " array([-6.84209561e-13,  2.35388983e-11, -6.97277800e-12]),\n",
       " array([-6.27906621e-07, -6.28505763e-07,  5.61310400e-07]),\n",
       " array([ 4.51557902e-06, -1.83065514e-05, -1.22046652e-06]),\n",
       " array([ 1.09750913e-11,  2.31173114e-11, -1.04726413e-10]),\n",
       " array([-1.73204511e-06,  7.95587341e-06,  1.06309173e-06]),\n",
       " array([-5.10900131e-08, -3.17181212e-08,  6.65161250e-09]),\n",
       " array([ 2.05372386e-18,  2.22175212e-21, -4.07103934e-18]),\n",
       " array([-3.57825584e-06, -2.88346862e-06, -2.22294853e-06]),\n",
       " array([4.14194597e-06, 4.92626435e-07, 9.72772185e-06]),\n",
       " array([-1.53748250e-10,  3.22938217e-10,  1.83181896e-08]),\n",
       " array([ 3.46855689e-05, -2.92727132e-05, -7.80769405e-05]),\n",
       " array([ 4.89362966e-05, -5.32502261e-05, -6.04259835e-05]),\n",
       " array([ 2.92290999e-06, -3.71790288e-06, -2.24050018e-06]),\n",
       " array([ 7.69901569e-06,  2.80918421e-06, -8.11558657e-06]),\n",
       " array([-2.78069623e-05,  1.96256541e-05, -1.15668050e-05]),\n",
       " array([-3.09332779e-06, -8.13771374e-08, -2.37294302e-06]),\n",
       " array([-2.79812550e-05,  2.54109628e-06,  1.90618949e-05]),\n",
       " array([ 2.11895973e-11, -1.38733908e-13, -1.40900370e-09]),\n",
       " array([-7.95427772e-08, -4.05207488e-06, -2.53132423e-06]),\n",
       " array([-7.51861978e-07,  2.79512847e-06, -3.36120811e-08]),\n",
       " array([-1.04026907e-08, -2.21058695e-08,  1.00226185e-07])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_predictions(n_state, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_step(state, minus_vdt=minus_vdt):\n",
    "    dses = make_predictions(state, model)\n",
    "    dvs = make_predictions(state, model_vel)\n",
    "    for atom_num in range(CFG.N):\n",
    "        # print(state[atom_num][1] * dt)\n",
    "        if minus_vdt:\n",
    "            state[atom_num][0] += state[atom_num][1] * dt     # ЕСЛИ ВЫЧИТАЛИ vdt при обучении\n",
    "        state[atom_num][0] += dses[atom_num]\n",
    "\n",
    "        state[atom_num][1] += dvs[atom_num]\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_cycle(state, number_of_steps, xyz_path=None, minus_vdt=minus_vdt):\n",
    "    '''\n",
    "    state: starting state\n",
    "    '''\n",
    "    # print(state)\n",
    "    for step in tqdm(range(number_of_steps)):\n",
    "        fill_csv(state, result_coords_csv)\n",
    "        fill_csv(state, result_vels_csv, mode=\"vels\")\n",
    "\n",
    "        state = make_step(state, minus_vdt=minus_vdt)\n",
    "\n",
    "        fill_csv(state, result_coords_csv)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_coords_csv, \"w\") as f:\n",
    "    f.truncate(0)\n",
    "    csv.DictWriter(f, fieldnames=csv_naming_coords).writeheader()\n",
    "\n",
    "with open(result_vels_csv, \"w\") as f:\n",
    "    f.truncate(0)\n",
    "    csv.DictWriter(f, fieldnames=csv_naming_coords).writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.66it/s]\n"
     ]
    }
   ],
   "source": [
    "integration_cycle(state=n_state, number_of_steps=1000, minus_vdt=minus_vdt)\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Проверка коэффициента диффузии:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_3_6_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b5cc6bf18c7103cb99324f044582e9ca68eda52a25f7227b20ca62cd3e32898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
