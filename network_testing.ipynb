{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создал этот ноутбук для проверки простеньких сеток на синтетических датасетах / кусках датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Векторы V все почти что коллинеарны, когда их много - стоит уже посмотреть на $p_i$ и $r_{cut_{i}}$\n",
    "\n",
    "- надо сделать нормализацию X и таргетов, причем для таргетов реализовать обратную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "\n",
    "from utility_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movements'"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset_objects/' + MODE + '/2_dataset_K_3.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    '''\n",
    "    Класс, нормализующий векторы\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.mu = 0.\n",
    "        self.std = 1.0\n",
    "\n",
    "    def normalize(self, data):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def inverse_normalize(self, vec):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    '''\n",
    "\n",
    "    All hyperparameters are here\n",
    "\n",
    "    '''\n",
    "\n",
    "    N = int(path.split(\"/\")[-1].split('_')[0])     # число атомов\n",
    "    K = int(path.split(\"/\")[-1].split('_')[-1].split('.')[0])     # можно называть это разрешением...чем число больше, тем больше размеры матрицы для атомов, фактически это число элементов в наборах p и r_cut\n",
    "\n",
    "    L = 2 * N ** (1 / 3) # размер одной клетки при моделировании\n",
    "\n",
    "    r_cut = np.random.uniform(low=5, high=10, size=K).copy()\n",
    "    p = np.random.uniform(low=1, high=3, size=K).copy()\n",
    "    N_neig= N - 1 if N != 2 else 1\n",
    "\n",
    "    # train_bs = 8\n",
    "    # val_bs = 16\n",
    "    batch_size = 128\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device=\"cpu\"\n",
    "\n",
    "    f_threshold = 5    # Если сила по какой-то координате превышает это значение, то строчка исключается, совсем маленьких по модулю сил быть не должно, если что при генерации просто r_cut поменьше надо делать\n",
    "    coord_threshold = L     # Если вдруг очень большие расстояния, то надо выкидывать\n",
    "    f_min_threshold = 0.05\n",
    "    #\n",
    "    output_size = K     # Размерность аутпута модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_and_get_quality(model, X_matrices=None, Y_target=None, figsize=(30, 20), fontsize=20, criterion=nn.MSELoss(), data=None, same_axis=False, show_3D_quality=False):\n",
    "    '''\n",
    "\n",
    "    Строит предсказанную и тагрет зависимости\n",
    "\n",
    "    Можно подавать либо отлельно X_matrices, Y_target либо подать датасет из тьюплов: (X, f_k_dim, f_3d, A_pinv)\n",
    "\n",
    "    Будет подаваться 3 итерируемых объекта: набор(батч или кусок датасета) из \"матриц\", предсказания, таргеты\n",
    "\n",
    "    returns: Y_pred, Y_target    \n",
    "    '''\n",
    "\n",
    "    if data:\n",
    "        X_matrices, Y_target, pinv_As, Y_target_3D = list(map(lambda x: torch.stack(x), list(zip(*data))))\n",
    "        \n",
    "    Y_pred = model(X_matrices)\n",
    "    metric = criterion(Y_pred, Y_target)\n",
    "    names = ['predicted', 'target']\n",
    "    Ys = [Y_pred, Y_target]\n",
    "    metric = criterion(Y_pred, Y_target)\n",
    "\n",
    "    maper = MeanAbsolutePercentageError()\n",
    "    mape = maper(Y_pred, Y_target)\n",
    "\n",
    "    if show_3D_quality:\n",
    "        outputs_3D = torch.bmm(pinv_As, torch.unsqueeze(Y_pred.to(torch.float), 2)).to(CFG.device)    # используются для вычисления MSE метрики уже на 3D векторах силы\n",
    "        outputs_3D = torch.squeeze(outputs_3D, -1)\n",
    "        metric_3d = criterion(outputs_3D, Y_target_3D)\n",
    "        mape_3d = maper(outputs_3D, Y_target_3D)\n",
    "    \n",
    "    print(\n",
    "        pinv_As[3] @ Y_target[3], Y_target_3D[3]\n",
    "    )\n",
    "\n",
    "    if not show_3D_quality:\n",
    "        print(f'MSE: {metric:.5f}, mape: {mape:.4f} %')\n",
    "    else:\n",
    "        print(f'MSE: {metric:.5f}, mape: {mape:.4f} %, MSE_for_3D_after_pinv_A: {metric_3d:.5f}, mape_3d: {mape_3d:.4f} %')\n",
    "\n",
    "    return Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, show_3D_quality):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    В данной версии: (X, f_k_dim)\n",
    "\n",
    "    Лосс выводится для k-мерного предсказания, а mse считается по 3D вариантам, однако при K=1 3d и 1d MSE совпадают\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels, pinv_As, labels_3D in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if show_3D_quality:\n",
    "            # print(pinv_As.size(), torch.unsqueeze(outputs.to(torch.float), 2).size())\n",
    "            outputs_3D = torch.bmm(pinv_As, torch.unsqueeze(outputs.to(torch.float), 2)).to(CFG.device)    # используются для вычисления MSE метрики уже на 3D векторах силы\n",
    "            outputs_3D = torch.squeeze(outputs_3D, -1)\n",
    "            running_MSE += F.mse_loss(input=outputs_3D, target=labels_3D, reduction='sum').item()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)    # при очень большом размере батча последние два батча будут например размера 128 вместо 256, поэтому просто умножать на батч сайз неправильно, могут быть другого размера\n",
    "        processed_size += inputs.size(0)\n",
    "\n",
    "    # print(labels)\n",
    "    train_loss = running_loss / processed_size\n",
    "    if show_3D_quality:\n",
    "        train_MSE = running_MSE / processed_size\n",
    "        return train_loss, train_MSE\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion, show_3D_quality):\n",
    "    '''\n",
    "\n",
    "    Одна эпоха по val выборке\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels, pinv_As, labels_3D in val_loader:\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        if show_3D_quality:\n",
    "            outputs_3D = torch.bmm(pinv_As, torch.unsqueeze(outputs.to(torch.float), 2)).to(CFG.device)    # используются для вычисления MSE метрики уже на 3D векторах силы\n",
    "            outputs_3D = torch.squeeze(outputs_3D, -1)\n",
    "            running_MSE += F.mse_loss(input=outputs_3D, target=labels_3D, reduction='sum').item()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)    # при очень большом размере батча последние два батча будут например размера 128 вместо 256, поэтому просто умножать на батч сайз неправильно, могут быть другого размера\n",
    "        processed_size += inputs.size(0)\n",
    "\n",
    "    # print(f' outputs:\\n{outputs}, \\n labels: \\n {labels}')\n",
    "    \n",
    "    val_loss = running_loss / processed_size\n",
    "    if show_3D_quality:\n",
    "        val_MSE = running_MSE / processed_size\n",
    "        return val_loss, val_MSE\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optimizer, scheduler=None, epochs=10, scaler=None, criterion=nn.MSELoss(), show_3D_quality=False, print_step=1):\n",
    "    '''\n",
    "\n",
    "    Basic option: calculation loss on K-dimensional outputs, but MSE metric on 3D outputs, after the matrix is applied\n",
    "\n",
    "    loss_on_k_projections: calculate loss'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    history = []\n",
    "    if show_3D_quality:\n",
    "        log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.6f} val_loss: {v_loss:0.6f} train_mse: {t_mse:0.6f} val_mse: {v_mse:0.6f}\"\n",
    "    else:\n",
    "        log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.6f} val_loss: {v_loss:0.6f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        for epoch in range(epochs):\n",
    "            if show_3D_quality:\n",
    "                train_loss, train_mse = fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, show_3D_quality)\n",
    "                val_loss, val_mse = eval_epoch(model, val_loader, criterion, show_3D_quality)\n",
    "            else:\n",
    "                train_loss = fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, show_3D_quality)\n",
    "                val_loss = eval_epoch(model, val_loader, criterion, show_3D_quality)\n",
    "            history.append((train_loss, val_loss))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            if epoch % print_step == 0:\n",
    "                if show_3D_quality:\n",
    "                    tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss, v_loss=val_loss, t_mse=train_mse, v_mse=val_mse))\n",
    "                else:\n",
    "                    tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss, v_loss=val_loss))\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNet(nn.Module):\n",
    "    '''\n",
    "\n",
    "    Класс одиночной нейронной сети\n",
    "\n",
    "    '''\n",
    "    def __init__(self, output_size, activation=nn.ReLU(), flattened_size=CFG.K * CFG.K):\n",
    "        '''\n",
    "        \n",
    "        FC_type: тип полносвязных слоев: 'regular' / 'simple\n",
    "\n",
    "        convolution: сверточная часть сети\n",
    "\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.BatchNorm1d(flattened_size),\n",
    "\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            # nn.Linear(128, 256),\n",
    "            # activation,\n",
    "            # # nn.Dropout(0.3),\n",
    "            # nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(128, 256),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "\n",
    "        # self.FC = nn.Linear(flattened_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x - is batch of matrices KxK\n",
    "\n",
    "        # Здесь происходят какие-то там свертки, пуллинги и тп..\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_dataloader, val_dataloader = recieve_loaders(\n",
    "    batch_size=CFG.batch_size,\n",
    "\n",
    "    # take_one_projection_for_data=0,\n",
    "    path=path,\n",
    "\n",
    "    cut_size=None,\n",
    "\n",
    "    # even_for_train=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама частица, отступаем от нее вектор силы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleNet(\n",
       "  (FC): Sequential(\n",
       "    (0): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=12, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SingleNet(\n",
    "    flattened_size=len(train_data[0][0]),\n",
    "\n",
    "    output_size=len(train_data[0][1]),\n",
    "\n",
    "    # activation=nn.Sigmoid(),\n",
    "    # activation=nn.Tanh(),\n",
    "    activation=nn.ReLU(),\n",
    "\n",
    ").to(CFG.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, betas=(0.9, 0.999), weight_decay=0.5)\n",
    "\n",
    "# scheduler.step нужно первый раз делать обязательно после optimizer.step, потому что иначе мы просто пропустим первый шаг scheduler\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   9%|▉         | 9/100 [00:00<00:02, 40.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 1.447278 val_loss: 0.002400 train_mse: 4.341834 val_mse: 0.007201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  61%|██████    | 61/100 [00:01<00:00, 52.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 051 train_loss: 0.000001 val_loss: 0.000001 train_mse: 0.000002 val_mse: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 100/100 [00:01<00:00, 50.32it/s]\n"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    train_loader=train_dataloader, val_loader=val_dataloader, model=model, optimizer=optimizer,\n",
    "    \n",
    "    scheduler=exp_scheduler,\n",
    "    scaler=None,\n",
    "    \n",
    "    # criterion=MultiOutputMSELoss(),     # on K=1 it's the same as nn.MSELoss\n",
    "    criterion=nn.MSELoss(),\n",
    "    # criterion = GaussianNLLLossWithReadyVar(),\n",
    "    # criterion=MeanAbsolutePercentageError(),\n",
    "\n",
    "    show_3D_quality=False if len(train_data[0][1]) == 1 else True,    # ПОКА ЧИСТО ТЕСТЮ НА ОДНОЙ ПРОЕКЦИИ И ТАМ РАЗМЕРНОСТИ НЕ СОВПАДАЮТ\n",
    "    \n",
    "    epochs=100,\n",
    "\n",
    "    print_step=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0000e-05, -2.0000e-05,  3.2000e-05]) tensor([-1.0000e-05, -2.0000e-05,  3.2000e-05])\n",
      "MSE: 0.00000, mape: 1.0816 %, MSE_for_3D_after_pinv_A: 0.00000, mape_3d: 1.0816 %\n"
     ]
    }
   ],
   "source": [
    "Y_pred, Y_target = make_predictions_and_get_quality(\n",
    "    model=model, data=val_data, same_axis=True,\n",
    "    show_3D_quality=False if len(train_data[0][1]) == 1 else True\n",
    "    )\n",
    "\n",
    "Y_true = Y_target.squeeze().detach().numpy()\n",
    "Y_pred = Y_pred.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.000e-05,  0.000e+00, -1.000e-05],\n",
       "       [ 6.000e-04,  2.074e-03,  1.280e-03],\n",
       "       [ 6.200e-04,  2.030e-03,  1.240e-03],\n",
       "       [-1.000e-05,  2.000e-05,  3.200e-05],\n",
       "       [-5.700e-04, -2.000e-03, -1.250e-03],\n",
       "       [ 3.600e-04,  1.180e-03,  7.200e-04],\n",
       "       [ 4.500e-04,  1.580e-03,  9.800e-04],\n",
       "       [ 2.300e-04,  7.620e-04,  4.400e-04],\n",
       "       [ 1.100e-04,  3.400e-04,  2.220e-04],\n",
       "       [-4.400e-04, -1.430e-03, -8.800e-04]], dtype=float32)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5743198e-06, 2.9560937e-05, 1.8285640e-05],\n",
       "       [9.7663624e-06, 3.1606985e-05, 1.9716128e-05],\n",
       "       [9.7374668e-06, 3.1308893e-05, 1.9523772e-05],\n",
       "       [9.8314795e-06, 3.1927608e-05, 2.0107675e-05],\n",
       "       [9.7155689e-06, 3.1075644e-05, 1.9365736e-05],\n",
       "       [9.7803013e-06, 3.1753963e-05, 1.9813539e-05],\n",
       "       [9.8351093e-06, 3.2034393e-05, 2.0167690e-05],\n",
       "       [9.7678740e-06, 3.1625295e-05, 1.9729408e-05],\n",
       "       [9.7068141e-06, 3.0975702e-05, 1.9281151e-05],\n",
       "       [9.7315633e-06, 3.1239691e-05, 1.9465957e-05]], dtype=float32)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Снизу пытаюсь как-то визуализировать предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = (torch.stack([elem[0] for elem in val_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "x11_val = val_X[:, 0]\n",
    "x22_val = val_X[:, 4]\n",
    "x33_val = val_X[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE != \"movements\":\n",
    "    plot_2d_result(\n",
    "        x11_val,\n",
    "        y_pred=Y_pred if len(train_data[0][1]) == 1 else [elem[0] for elem in Y_pred],\n",
    "        y_true=Y_true if len(train_data[0][1]) == 1 else [elem[0] for elem in Y_true],\n",
    "        figsize=(20, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(X, Y_pred, Y_true, figsize=(15, 15)):\n",
    "    '''\n",
    "    Function which plots matrix of dependencies: f_i(X_jj)\n",
    "    '''\n",
    "    k = len(Y_pred[0])\n",
    "    fig, axes = plt.subplots(k, k, figsize=figsize)\n",
    "\n",
    "    for i in range(k):  # цикл по компонентам силы\n",
    "        y_pred = [elem[i] for elem in Y_pred]\n",
    "        y_true = [elem[i] for elem in Y_true]\n",
    "        for j in range(k):\n",
    "            x = [elem.reshape(CFG.K, CFG.K)[j][j] for elem in X]\n",
    "            axes[i][j].set_title(f'$f_{i}(X_{str(j)})$')\n",
    "            axes[i][j].scatter(x, y_pred, label=\"Predicted\", s=10)\n",
    "            axes[i][j].scatter(x, y_true, label=\"True\", s=10)\n",
    "            axes[i][j].legend(loc=\"best\")\n",
    "\n",
    "if MODE != \"movements\":\n",
    "    plot_matrix(\n",
    "        X=val_X,\n",
    "        Y_pred=Y_pred,\n",
    "        Y_true=Y_true,\n",
    "\n",
    "        figsize=(20, 20)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой вариант:\n",
    "\n",
    "Обучиться предсказывать элементарное перемещение по радиус вектору + вектору скорости (пока без скоростей)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без скоростей - предсказание перемещения эквивалентно предсказанию силы:\n",
    "\n",
    "$$\n",
    "r(t+\\Delta t) = r(t) v(t)\\Delta t + \\dfrac{1}{2}a(t)(\\Delta t)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "r(t+\\Delta t) - r(t) = v(t)\\Delta t + \\dfrac{1}{2}a(t)(\\Delta t)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ща два важных момента:\n",
    "- эксопнента в формуле \n",
    "- пока матрица остается диагональной\n",
    "\n",
    "- ITEM: TIMESTEP - это шаг интегратора; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ща: надо обучить предсказывать элементарное перемещение - если пока не сработает на только координатах, то это норм, так как нужны еще скорости, но вообще скорости, координаты и силы - все это связано весьма явно: ускорение по предположению явная функция только координат, а остальнлое интегрированием"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короче: Имея координаты мы же можем предсказать силу, а из формулы верле это дает нам, что мы можем элементарное смещение за $\\Delta$, зная скорости и координаты предсказать, поэтому текущая задача: на координатах обучиться предсказывать уже не силу, а элементарное смещение - так как наша задача интегрировать уравнения движения, еще раз скажу, что без скорости оно может не получиться и получение элементарного смещения вообще говоря может быть надо делать 2 моделями: одна по "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Добавить в выпрямленную матрицу X в конец 3 числа: vx, vy, vz\n",
    "- Для двух частиц \"невращающихся\" на матрице X из векторов V - которые по функции Леннарда Джонса на K = 3 на диагональной матрцие посчитаны\n",
    "\n",
    "**Обучаем на перемещения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0816)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor(Y_true)\n",
    "preds = torch.tensor(Y_pred)\n",
    "\n",
    "mean_abs_percentage_error = MeanAbsolutePercentageError()\n",
    "mean_abs_percentage_error(preds, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('my_3_6_conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b5cc6bf18c7103cb99324f044582e9ca68eda52a25f7227b20ca62cd3e32898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
