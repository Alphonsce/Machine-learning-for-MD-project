{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations:\n",
    "\n",
    "- выборка - тензор из картинок, таргет - вектор силы\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы используют multi output GPR, настраивая гиперпараметры $\\sigma_{cov}$ и $\\sigma_{err}$ (можно однозначно их выразить через гиперпараметры из того же sklearn: $l$ и $\\sigma$)\n",
    "\n",
    "GPR - непараметрический метод, суть в том, что мы делаем предположение о виде матрицы корреляции признаков для известных данных.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моделирование в хотя бы немного более сложном случае буду писать на Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры:\n",
    "\n",
    "1)k: Количество элементов в массивах r_cut и p для каждого атома\n",
    "\n",
    "2)$r_{cut}(i)_j$, i=1..k, j=1..N: векторы r_cut для j атома тоже параметр\n",
    "\n",
    "3)$p_(i)_j$, i=1..k, j=1..N: векторы p для j атома тоже параметр\n",
    "\n",
    "4)N_neighbours for summation for IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В GPyTorch есть имплементация многоразмерного регрессора: https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/index.html#multi-output-vector-valued-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Пока что все размерности предполагаются в системе LJ, потому что пока пытаюсь это зафитить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходно пока в coords.csv и forces.csv находятся для 2 частиц данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp36-cp36m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 8.6 MB/s            \n",
      "\u001b[?25hCollecting torch==1.10.1\n",
      "  Downloading torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 14 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/alphonse/anaconda3/lib/python3.6/site-packages (from torchvision) (1.19.2)\n",
      "Collecting pillow!=8.3.0,>=5.3.0\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     |████████████████████████████████| 3.1 MB 11.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /home/alphonse/anaconda3/lib/python3.6/site-packages (from torch==1.10.1->torchvision) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/alphonse/anaconda3/lib/python3.6/site-packages (from torch==1.10.1->torchvision) (4.1.1)\n",
      "Installing collected packages: torch, pillow, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.2\n",
      "    Uninstalling torch-1.10.2:\n",
      "      Successfully uninstalled torch-1.10.2\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 4.2.1\n",
      "    Uninstalling Pillow-4.2.1:\n",
      "      Successfully uninstalled Pillow-4.2.1\n",
      "Successfully installed pillow-8.4.0 torch-1.10.1 torchvision-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from numba import jit, njit, vectorize\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.linalg import norm as norm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''\n",
    "    \n",
    "    Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.\n",
    "\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    '''\n",
    "\n",
    "    All hyperparameters are here\n",
    "\n",
    "    '''\n",
    "\n",
    "    N = 2     # число атомов\n",
    "    K = 2     # можно называть это разрешением...чем число больше, тем больше размеры матрицы для атомов, фактически это число элементов в наборах p и r_cut\n",
    "\n",
    "    L = L = 2 * N ** (1 / 3) # размер одной клетки при моделировании\n",
    "\n",
    "    p = (np.random.rand(K) + 0.1).copy()\n",
    "    r_cut = (np.random.rand(K) + 0.1).copy()\n",
    "\n",
    "    N_neig= N - 1 if N != 2 else 1\n",
    "\n",
    "    # train_bs = 8\n",
    "    # val_bs = 16\n",
    "    batch_size = 256\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    f_threshold = 10    # Если сила по какой-то координате превышает это значение, то строчка исключается, совсем маленьких по модулю сил быть не должно, если что при генерации просто r_cut поменьше надо делать\n",
    "    coord_threshold = 2 * L     # Если вдруг очень большие расстояния, то надо выкидывать\n",
    "    #\n",
    "    output_size = 3     # Размерность аутпута модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется два .csv файла:\n",
    "\n",
    "1)\n",
    "| Id(time) | 1_x | 1_y | 1_z | ... | N_z |\n",
    "|------|-----|-----|-----|-----|-----|\n",
    "|      |     |     |     |     |     |\n",
    "|      |     |     |     |     |     |\n",
    "2)\n",
    "| Id(time) | f_1_x | f_1_y | f_1_z | ... | f_N_z |\n",
    "|------|-----|-----|-----|-----|-----|\n",
    "|      |     |     |     |     |     |\n",
    "|      |     |     |     |     |     |\n",
    "\n",
    "Одна строчка отсюда превращается в N матриц (на каждый атом) с N векторами сил\n",
    "\n",
    "В идеале сделать БДху из двух сущностей: сила и координата, где полями будут их проекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_coords(coords_file_path = None, forces_file_path = None):\n",
    "    '''\n",
    "    just makes df from .csvs with coords and forces\n",
    "    '''\n",
    "    coords = pd.read_csv(coords_file_path)\n",
    "\n",
    "    forces = pd.read_csv(forces_file_path)\n",
    "\n",
    "    if CFG.N != int(coords.columns[-1][:-1]) + 1:\n",
    "        raise Exception('Constant N is not equal to amount of particles in .csv')\n",
    "\n",
    "    return pd.merge(left=coords, right=forces, on='t').drop('t', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set([1, 2])\n",
    "b = set([2, 3])\n",
    "\n",
    "a.union(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 индекс - 1 отн 2\n",
    "\n",
    "$$\n",
    "\\vec{r_1} = \\vec{r_2} + \\vec{r}_{12}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{r}_{12} = \\vec{r_1} - \\vec{r}_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_positions(row, atom_number):\n",
    "    '''\n",
    "    This function processes one row of csv into something that we can work with\n",
    "\n",
    "    Returns np.array matrix that consists of relative positions vectors for passed atom_number to every other atom\n",
    "    and then we can chose only closest N_neighbours in the next functions\n",
    "    \n",
    "    row: df.iloc[row] - typeof(row): pd.Series\n",
    "    \n",
    "    returns: Rel_matrix, f_vec\n",
    "    '''\n",
    "\n",
    "    s_coord = pd.Series(dtype=float)\n",
    "    other_atom_numbers = [i for i in range(CFG.N) if i != atom_number]\n",
    "\n",
    "    for other_numb in other_atom_numbers:\n",
    "        index = str(atom_number) + str(other_numb)\n",
    "        for axis in ['x', 'y', 'z']:\n",
    "            s_coord[index + axis] = row[str(atom_number) + axis] - row[str(other_numb) + axis]\n",
    "\n",
    "    # we need force vector only for atom_number:\n",
    "    force_vec = []\n",
    "    for f_axis in ['f_x', 'f_y', 'f_z']:\n",
    "        force_vec.append(row[str(atom_number) + f_axis])\n",
    "        \n",
    "\n",
    "    Rel_matrix = []\n",
    "    cur_vector = []\n",
    "\n",
    "    for (i, elem) in enumerate(s_coord.values):\n",
    "        if i % 3 == 0 and i != 0:\n",
    "            Rel_matrix.append(cur_vector)\n",
    "            cur_vector = []\n",
    "\n",
    "        cur_vector.append(elem)\n",
    "    Rel_matrix.append(cur_vector)\n",
    "\n",
    "    return np.array(Rel_matrix), np.array(force_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def make_one_vec_transformed(vec, vec_norm, r_cut_i, p_i):\n",
    "    '''\n",
    "    vec: np.array - normalized vector\n",
    "    norm: its norm\n",
    "    r_cut_i: i-th component of\n",
    "    '''\n",
    "    return vec * np.exp(\n",
    "        -np.power((vec_norm / r_cut_i), p_i)\n",
    "        )\n",
    "\n",
    "make_matrix_transformed = np.vectorize(make_one_vec_transformed)\n",
    "\n",
    "def create_V_i(i, normalized_m, norms, r_cut=CFG.r_cut, p=CFG.p):\n",
    "    '''\n",
    "    normalized_m: matrix of relative distances, where rows - normalized vectors\n",
    "    i: i-th component of r_cut and p, i in range 1..K (or in 0..K-1 in code)\n",
    "    '''\n",
    "    transf_vecs = make_matrix_transformed(normalized_m, norms[:, np.newaxis], r_cut[i], p[i])\n",
    "\n",
    "    return np.sum(transf_vecs, axis=0)\n",
    "\n",
    "# @njit(parallel=True)\n",
    "def create_V(normalized_m, norms, K=CFG.K):\n",
    "    '''\n",
    "    creates V\n",
    "    '''\n",
    "    V = []\n",
    "    for i in range(K):\n",
    "        V.append(\n",
    "            create_V_i(i, normalized_m, norms)\n",
    "        )\n",
    "\n",
    "    return np.array(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit(\n",
    "#     # parallel=True,\n",
    "#     # fastmath=True\n",
    "#     )\n",
    "def _calculate_matrix_for_atom(relative_distances, r_cut=CFG.r_cut, p=CFG.p, N_neig=CFG.N_neig, K=CFG.K):\n",
    "    '''\n",
    "\n",
    "    relative_distances: np.array matrix of relative distance vectors\n",
    "\n",
    "    '''\n",
    "\n",
    "    norms = norm(relative_distances, axis=-1)\n",
    "    \n",
    "    # Only closest N_neig are counting:\n",
    "    indexlist = np.argsort(norm(relative_distances, axis=1))\n",
    "    relative_distances = relative_distances[indexlist[len(relative_distances) - N_neig:]]\n",
    "\n",
    "    normalized_rel_distances = relative_distances / norms[:, np.newaxis]\n",
    "\n",
    "    # print(\n",
    "    #     create_V_i(0, normalized_rel_distances, norms), f'{CFG.r_cut=}, {CFG.p=}'\n",
    "    # )\n",
    "\n",
    "    V = create_V(normalized_rel_distances, norms)\n",
    "\n",
    "    # print(f'V:\\n {V}\\n norms:\\n {norm(V, axis=-1)[:, np.newaxis]}\\n normed_V:\\n {V / norm(V, axis=-1)[:, np.newaxis]}')\n",
    "    \n",
    "    # print(V / norm(V, axis=-1)[:, np.newaxis])\n",
    "    if np.inf in V / norm(V, axis=-1)[:, np.newaxis] or np.nan in V / norm(V, axis=-1)[:, np.newaxis]:\n",
    "        print(f'V:\\n {V}\\n norms:\\n {norm(V, axis=-1)[:, np.newaxis]}\\n normed_V:\\n {V / norm(V, axis=-1)[:, np.newaxis]}')\n",
    "        print(f'ABOUT RELATIVE DISTANCES:\\n rel_dists:\\n {relative_distances}\\n norms:\\n{norms}\\n normalized_rel_dists:\\n {normalized_rel_distances}')\n",
    "\n",
    "    A = V / norm(V, axis=-1)[:, np.newaxis]\n",
    "\n",
    "    X = V @ A.T\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_for_atom(row = None, atom_number = None):\n",
    "    '''\n",
    "\n",
    "    This function will create X matrix for passed atom with\n",
    "    arrays of r_cut and p of length k\n",
    "\n",
    "    It is a wrapper for _get_relative_positions and _calculate_matrix_for_atom, so I can speed up matrix calculations\n",
    "    with numba for _calculate_matrix_for_atom\n",
    "\n",
    "    atom_number: a number of atom that we are passing\n",
    "    row: one row from df_with_coords, i.e. df.iloc[index_of_row]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # creating row of relative coordinates for concrete atom:\n",
    "    relative_distances, f_vec = _get_relative_positions(row=row, atom_number=atom_number)\n",
    "    X = _calculate_matrix_for_atom(relative_distances=relative_distances)\n",
    "    \n",
    "    return X, f_vec\n",
    "\n",
    "# %timeit get_matrix_for_atom(row=df.iloc[0], atom_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**У нас будет train и val выборки, все-таки выборку, для который известен таргет принято называть validation, на которой мы качество оцениваем, а test это все-таки выборка, для который неизвестны таргеты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df: pd.DataFrame, f_threshold = CFG.f_threshold, coord_threshold=CFG.coord_threshold):\n",
    "    '''\n",
    "\n",
    "    Убирает строчки с аномально большими силами из df\n",
    "\n",
    "    '''\n",
    "\n",
    "    indexes_for_deletion = set()\n",
    "\n",
    "    for numb in range(CFG.N):\n",
    "        for coord in ['f_x', 'f_y', 'f_z']:\n",
    "\n",
    "            indexes_for_deletion = indexes_for_deletion.union(\n",
    "                set(df[abs(df[str(numb) + coord]) > f_threshold].index)\n",
    "            )\n",
    "\n",
    "        for coord in ['x', 'y', 'z']:\n",
    "            indexes_for_deletion = indexes_for_deletion.union(\n",
    "                set(df[abs(df[str(numb) + coord]) > coord_threshold].index)\n",
    "            )\n",
    "\n",
    "    return df.drop(list(indexes_for_deletion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(coords_file_path = 'coords.csv', forces_file_path = 'forces.csv', step=1, transform=transforms.ToTensor(), length=None,\n",
    "    f_threshold=CFG.f_threshold, coord_threshold=CFG.coord_threshold):\n",
    "    '''\n",
    "\n",
    "    Примитивная версия датасета, просто все будет хранить в одном тензоре...\n",
    "\n",
    "    Эта функция - wrapper на все выше написанные функции, она по переданным путям к .csv\n",
    "    возвращает тензор из матриц для каждого атома в каждой строчке и тензор из векторов сил\n",
    "\n",
    "\n",
    "    ИНогда есть смысл делать побольше шаг между соседними строчками, поскольку если есть почти одинаковые матрицы, то\n",
    "    это по-сути линейная зависимость и модель тогда надо сильнее регулизировать\n",
    "\n",
    "    transform: преобразование к X части датасета, в основном для нормализации нужно\n",
    "    step: через сколько строчек шагать при чтении csv в датасет, чтобы уж совсем одинаковых не было\n",
    "\n",
    "    '''\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    df = create_df_with_coords(coords_file_path=coords_file_path, forces_file_path=forces_file_path)\n",
    "    if length:\n",
    "        df = df.loc[range(length)]\n",
    "\n",
    "    # Сюда будет вставлена чистка df от больших сил\n",
    "    df = clean_df(df, f_threshold=f_threshold, coord_threshold=coord_threshold)\n",
    "\n",
    "    row_indexes = [i for i in range(0, len(df.index), step)]\n",
    "\n",
    "    for atom_number in range(CFG.N):\n",
    "        for index in tqdm(row_indexes, desc=f'Progress for atom {atom_number}'):\n",
    "            row = df.iloc[index]\n",
    "            x, f = get_matrix_for_atom(row=row, atom_number=atom_number)\n",
    "\n",
    "            if transform:\n",
    "                x = transform(x)\n",
    "            else:\n",
    "                x = transforms.ToTensor()(x)\n",
    "            x = x.to(torch.float)\n",
    "\n",
    "            dataset.append(\n",
    "                (x, torch.tensor(f, dtype=torch.float))\n",
    "                )\n",
    "            \n",
    "            # В дальнейшем для других моделей может иметь смысл хранить и возвращать тут (x, f, A), где A - соответствующая матрица для X\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Когда только начинаю работать с датасетом надо один раз на трейне посчитать std и mean, чтобы нормализовать можно было\n",
    "\n",
    "mean = 0.1193004623055458\n",
    "std = 0.09002102166414261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все-таки у нас тут не картинки будут, поэтому я попробую сначала даже без нормализации, нормализовать надо 1 канал, если в терминах картинки рассуждать\n",
    "\n",
    "transform = transforms.Compose([                                    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress for atom 0: 100%|██████████| 932/932 [00:05<00:00, 159.44it/s]\n",
      "Progress for atom 1: 100%|██████████| 932/932 [00:01<00:00, 674.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset = create_tensor_dataset('coords.csv', 'forces.csv', step=20)\n",
    "\n",
    "# Uncomment, when calculated and changed mean and std:\n",
    "\n",
    "dataset = create_tensor_dataset('coords.csv', 'forces.csv', step=20, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока никакие параметры особо не надо настраивать, поэтому и кросс валидацию не буду делать пока что, затем ее можно сделать, передавая в функцию create_dataloaders еще один параметр - фолд, на котором трейн, предварительно поделив на фолды датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если просто брать в качестве трейна другие строчки из одной генерации, то можно не отследить переобучения, стоит пробовать тестить на датасете, который отдельно сгенерирован с таким же числом частиц, который модель еще вообще не видела"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 2]), tensor([[[1.7375, 1.7375],\n",
       "          [0.0275, 0.0275]]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.33, random_state=42)\n",
    "\n",
    "train_data[62][0].size(), train_data[62][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Код для выяснения mean и std у трейновой выборки и для проверки уже после нормализации: (по ненормализованному датасету делается)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 1.7117231720931159e-07, std = 1.0\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std_for_train_X(train_data):\n",
    "    train_X = torch.cat([row[0] for row in train_data])\n",
    "\n",
    "    print(\n",
    "        f'mean = {torch.mean(train_X)}, std = {torch.std(train_X)}'\n",
    "    )\n",
    "\n",
    "get_mean_and_std_for_train_X(train_data=train_data) # тупо проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Когда молекул уже будет много как хранить данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта клетка нужна будет, когда молекул будет много (N > 100, K порядка 100)\n",
    "\n",
    "def create_df_with_paths(df_coords: pd.DataFrame, first_folder = 'Atom_matrices'):\n",
    "    '''\n",
    "\n",
    "    Пока эта функция не нужна, но в будущем за счет нее как раз будет работать PathBasedDataset\n",
    "\n",
    "    gets df, returns df with paths to torch matrices for each atom for different times,\n",
    "    basically this function will call get_matrix_for_atom a lot of times\n",
    "\n",
    "    output: pd.DataFrame that orignated from this:\n",
    "    \n",
    "    | Index | 1_atom_X_path                     | ... | N_atom_X_path                     |\n",
    "    |-------|-----------------------------------|-----|-----------------------------------|\n",
    "    | 1     | ./atom_matrices/index1/atom1.tb   |     | ./atom_matrices/index1/atomN.tb   |\n",
    "    | ...   |                                   |     |                                   |\n",
    "    | 30k   | ./atom_matrices/index30k/atom1.tb |     | ./atom_matrices/index30k/atomN.tb |\n",
    "    \n",
    "    but eventually will look like this:\n",
    "\n",
    "    | Index   | atom_X_path                       |\n",
    "    |---------|-----------------------------------|\n",
    "    | 1       | ./atom_matrices/index1/atom1.tb   |\n",
    "    | ...     | ...                               |\n",
    "    | 30k * N | ./atom_matrices/index30k/atomN.tb |\n",
    "\n",
    "    '''\n",
    "    row_numbers = df_coords.index\n",
    "\n",
    "    df_paths = pd.DataFrame(\n",
    "        {\n",
    "            'path': []\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pass\n",
    "\n",
    "class PathBasedDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "\n",
    "    Это будет класс датасета из торча для большого числа молекул, если молекул будет очень много, то надо будет уже хранить все матрицы X не в оперативной памяти\n",
    "\n",
    "    При создании экземпляра будет передаваться pd.Dataframe, который\n",
    "    состоит из трех колонок - проекций вектора силы и еще одной колонки - путь к файлу, где лежит как-то заэнкоженная\n",
    "    матрица для данного атома, и так для каждого атома (я проверил, что запись и чтение при помощи torch.save и torch.load для тензоров очень быстрое)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, df, transforms=None, mode='train'):\n",
    "        self.df = df    # it will be dataframe with coordinates and forces of all atoms\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = 1   # it will be a matrix KxK for each atom\n",
    "        y = 1   # it will be a force vector with shape: (3)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, train_bs=CFG.batch_size, val_bs=CFG.batch_size, fold=None):\n",
    "    '''\n",
    "\n",
    "    Returns train_loader, val_loader\n",
    "\n",
    "    fold: will be used in cross validation, when I will implement it\n",
    "\n",
    "    '''\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=val_bs, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_dataloaders(train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 2, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].size()  # [batch_size, Channels, Height, Width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-2982c1b094ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msetuptools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLooseVersion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я попробую оба варианта:\n",
    "1) Многомерный аутпут\n",
    "2) Для каждой компоненты свой одномерный аутпут\n",
    "\n",
    "надо помнить, что сначала на двух частицах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)Многомерный аутпут:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще постоянный множитель - это не особо важно, но просто при оценке качества модели возникнут определенные трудности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultuOutputMSELoss(nn.MSELoss):\n",
    "    '''\n",
    "\n",
    "    Custom loss that calculates average over batch loss for multidim MSE - sum of MSE for components\n",
    "\n",
    "    Example:\n",
    "    |\n",
    "    |    Loss = MultuOutputMSELoss()\n",
    "    |\n",
    "    |    a = torch.ones((8, 3))      # it is batch of 8 vectors of size 3\n",
    "    |    b = torch.zeros((8, 3))\n",
    "    |\n",
    "    |    Loss(a, b, batch_size=8) -> 3\n",
    "\n",
    "    '''\n",
    "\n",
    "    def forward(self, input, target, batch_size=CFG.batch_size):\n",
    "        '''\n",
    "        оно при reduction='mean' делит на произведение всех размерностей\n",
    "        '''\n",
    "        return F.mse_loss(input, target, reduction='sum') / batch_size   # или эквивалентно делать reduction='mean' и умножать на input.size()[-1] - length of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flattener(torch.nn.Module):\n",
    "    '''\n",
    "\n",
    "    Module that flattens the input\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()    \n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1865,  1.1865, -0.7085, -0.7085],\n",
       "        [ 1.2086,  1.2086, -0.6849, -0.6849],\n",
       "        [ 0.3387,  0.3387, -1.2479, -1.2479],\n",
       "        ...,\n",
       "        [ 0.8630,  0.8630, -0.9959, -0.9959],\n",
       "        [ 0.6905,  0.6905, -1.1058, -1.1058],\n",
       "        [ 1.7968,  1.7968,  0.1238,  0.1238]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl = flattener()\n",
    "\n",
    "fl(next(iter(train_loader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNet(nn.Module):\n",
    "    '''\n",
    "\n",
    "    Класс одиночной нейронной сети\n",
    "\n",
    "    '''\n",
    "    def __init__(self, output_size, convolution=None, activation=nn.ReLU(), flattened_size=CFG.K * CFG.K):\n",
    "        '''\n",
    "        \n",
    "        FC_type: тип полносвязных слоев: 'regular' / 'simple\n",
    "\n",
    "        convolution: сверточная часть сети\n",
    "\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = flattener()\n",
    "\n",
    "        if convolution:\n",
    "            self.conv_layers = convolution\n",
    "\n",
    "        # self.FC = nn.Sequential(\n",
    "        #     nn.Linear(flattened_size, 1024),\n",
    "        #     activation,\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 512),\n",
    "        #     activation,\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.Linear(512, 256),\n",
    "\n",
    "        #     nn.Linear(256, 128),\n",
    "        #     activation,\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.Linear(128, output_size)\n",
    "        # )\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x - is batch of matrices KxK\n",
    "\n",
    "        # Здесь происходят какие-то там свертки, пуллинги и тп..\n",
    "\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики буду использовать сумму MSE по компонентам, лоссы попробую разные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler=None):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum').item()\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_MSE = running_MSE / processed_data\n",
    "    \n",
    "    return train_loss, train_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    '''\n",
    "\n",
    "    Одна эпоха по val выборке\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # print(f' outputs:\\n{outputs}, \\n labels: \\n {labels}')\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum')\n",
    "        processed_size += inputs.size(0)\n",
    "\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_MSE = running_MSE.double().item() / processed_size\n",
    "    \n",
    "    return val_loss, val_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optimizer, scheduler, epochs, scaler=None, criterion=MultuOutputMSELoss()):\n",
    "    '''\n",
    "\n",
    "    Полный цикл обучения\n",
    "    \n",
    "    '''\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss {v_loss:0.4f} train_MSE {t_mse:0.4f} val_MSE {v_mse:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_MSE = fit_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "            val_loss, val_MSE = eval_epoch(model, val_loader, criterion)\n",
    "            if epoch != 0:\n",
    "                if history[-1][-1] < val_MSE:\n",
    "                    torch.save(model.state_dict(), './model.pth')     # сохраняем модель напрямую в гугл диск \n",
    "            \n",
    "            history.append((train_loss, train_MSE, val_loss, val_MSE))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss, v_loss=val_loss, t_mse=train_MSE, v_mse=val_MSE))\n",
    "            \n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "__conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(num_features=3),\n",
    "\n",
    "            # nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3),\n",
    "            # activation,\n",
    "            # nn.MaxPool2d(kernel_size=3),\n",
    "            # nn.BatchNorm2d(num_features=8)\n",
    "\n",
    "            flattener()\n",
    ")\n",
    "\n",
    "# Код для проверки длины конкатенированного вектора на вход в FC:\n",
    "\n",
    "# t = next(iter(train_loader))\n",
    "# a = conv_layers(t[0])\n",
    "# a.size()\n",
    "# a.view(a.size(0), -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleNet(\n",
    "    output_size=CFG.output_size,\n",
    "    # activation=nn.Tanh(),\n",
    "    convolution=None,\n",
    "    ).to(CFG.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), weight_decay=0.1)\n",
    "\n",
    "# scheduler.step нужно первый раз делать обязательно после optimizer.step, потому что иначе мы просто пропустим первый шаг scheduler\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleNet(\n",
       "  (conv_layers): flattener()\n",
       "  (FC): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  70%|███████   | 14/20 [00:00<00:00, 73.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 1.8483 val_loss 1.7006 train_MSE 1.9071 val_MSE 1.8724\n",
      "\n",
      "Epoch 002 train_loss: 1.4216 val_loss 1.6568 train_MSE 1.4405 val_MSE 1.8245\n",
      "\n",
      "Epoch 003 train_loss: 1.0648 val_loss 1.6503 train_MSE 1.0887 val_MSE 1.8187\n",
      "\n",
      "Epoch 004 train_loss: 0.9601 val_loss 1.6595 train_MSE 1.0024 val_MSE 1.8307\n",
      "\n",
      "Epoch 005 train_loss: 0.8660 val_loss 1.6624 train_MSE 0.8840 val_MSE 1.8351\n",
      "\n",
      "Epoch 006 train_loss: 0.8400 val_loss 1.6655 train_MSE 0.8617 val_MSE 1.8389\n",
      "\n",
      "Epoch 007 train_loss: 0.8413 val_loss 1.6678 train_MSE 0.8611 val_MSE 1.8416\n",
      "\n",
      "Epoch 008 train_loss: 0.8413 val_loss 1.6737 train_MSE 0.8574 val_MSE 1.8484\n",
      "\n",
      "Epoch 009 train_loss: 0.8205 val_loss 1.6821 train_MSE 0.8470 val_MSE 1.8582\n",
      "\n",
      "Epoch 010 train_loss: 0.8308 val_loss 1.6926 train_MSE 0.8556 val_MSE 1.8705\n",
      "\n",
      "Epoch 011 train_loss: 0.8183 val_loss 1.7104 train_MSE 0.8339 val_MSE 1.8917\n",
      "\n",
      "Epoch 012 train_loss: 0.8134 val_loss 1.7289 train_MSE 0.8398 val_MSE 1.9138\n",
      "\n",
      "Epoch 013 train_loss: 0.8452 val_loss 1.7478 train_MSE 0.8546 val_MSE 1.9361\n",
      "\n",
      "Epoch 014 train_loss: 0.8326 val_loss 1.7671 train_MSE 0.8420 val_MSE 1.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 20/20 [00:00<00:00, 65.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 015 train_loss: 0.8257 val_loss 1.7812 train_MSE 0.8495 val_MSE 1.9753\n",
      "\n",
      "Epoch 016 train_loss: 0.8399 val_loss 1.7958 train_MSE 0.8489 val_MSE 1.9924\n",
      "\n",
      "Epoch 017 train_loss: 0.8402 val_loss 1.8061 train_MSE 0.8543 val_MSE 2.0047\n",
      "\n",
      "Epoch 018 train_loss: 0.8326 val_loss 1.8163 train_MSE 0.8443 val_MSE 2.0168\n",
      "\n",
      "Epoch 019 train_loss: 0.8305 val_loss 1.8243 train_MSE 0.8420 val_MSE 2.0266\n",
      "\n",
      "Epoch 020 train_loss: 0.8246 val_loss 1.8256 train_MSE 0.8443 val_MSE 2.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    train_loader=train_loader, val_loader=val_loader, model=model, optimizer=optimizer,\n",
    "    scheduler=exp_scheduler, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history, figsize=(40, 15)):\n",
    "    '''\n",
    "\n",
    "    history: [(train_loss, train_MSE, val_loss, val_MSE), ...]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # writer = SummaryWriter()\n",
    "    \n",
    "    figure = plt.figure(figsize=figsize)\n",
    "\n",
    "    train_loss = [tup[0] for tup in history]\n",
    "    train_MSE = [tup[1] for tup in history]\n",
    "    val_loss = [tup[2] for tup in history]\n",
    "    val_MSE = [tup[3] for tup in history]\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(range(1, len(history) + 1), train_loss, label='train_loss')\n",
    "    plt.plot(range(1, len(history) + 1), val_loss, label='val_loss')\n",
    "    \n",
    "    plt.title('Losses', fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)     \n",
    "    plt.xticks(np.arange(1, len(history) + 1, 1))\n",
    "    # plt.yticks(np.arange(1, len(history) + 1, 1))\n",
    "    plt.legend(loc='best')\n",
    "    #\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(range(1, len(history) + 1), train_MSE, label='train_MSE')\n",
    "    plt.plot(range(1, len(history) + 1), val_MSE, label='val_MSE')\n",
    "    \n",
    "    plt.title('Metrics', fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)     \n",
    "    plt.xticks(np.arange(1, len(history) + 1, 1))\n",
    "    # plt.yticks(np.arange(1, len(history) + 1, 1))\n",
    "    plt.legend(loc='best', fontsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbcaed215c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Output_size сеток с одномерным аутпутом (предполагаем независимость всех компонент силы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто обучаю набор сеток на задачу регрессии, в качестве метрики для каждой сетки буду использовать MSE, а итоговая метрика - сумма MSE для каждой сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Просто делаю массив из экземпляров сеток, optim-ов, loss-ов и потом циклом по ним делаю ровно тот же самый вызов history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всем сеткам делаю абсолютно одинаковые гиперпараметры\n",
    "\n",
    "models = [SingleNet(output_size=1) for _ in range(CFG.output_size)]\n",
    "\n",
    "lr = 4e-3\n",
    "betas=(0.9, 0.999)\n",
    "weight_decay=0.1\n",
    "\n",
    "optims = [optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay) for model in models]\n",
    "\n",
    "step_size = 5\n",
    "gamma = 0.1\n",
    "\n",
    "exp_schedulers = [lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) for optimizer in optims]\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое главное при обучении этих моделей - то что у model[ i ] - таргет - это число force[ i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    '''\n",
    "    \n",
    "    Возвращает словарь из history для всех моделей: {1: history, 2: history, ...}\n",
    "\n",
    "    '''\n",
    "\n",
    "    histories = defaultdict(list)\n",
    "\n",
    "    # Надо менять немного цикл обучения, чтобы таргетом для i сетки была i-ая компонента вектора силы\n",
    "\n",
    "    # for i in range(CFG.output_size):\n",
    "    #     histories[str(i)] = train(\n",
    "    #         train_loader=train_loader,\n",
    "    #         val_loader=val_loader,\n",
    "    #         model=model,\n",
    "    #         optimizer=optimizer,\n",
    "    #         scheduler=exp_scheduler,\n",
    "    #         criterion=nn.MSELoss(),\n",
    "    #         epochs=10\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) GPR модель \n",
    "    - (потом можно сюда навалить и сетку в качестве ядра и вообще deep GP юзать, плюс еще feature extractor в виде сверток юзать сначала, если очень большая матрица, но сначала надо обычный сделать)\n",
    "\n",
    "## 3.1) Не стохастический подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html - как обучать модели в gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.gpytorch.ai/en/v1.3.1/examples/04_Variational_and_Approximate_GPs/SVGP_Regression_CUDA.html - как обучать GP по мини батчам, когда данных слишком много"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У авторов $C_{mn}$ - это матрица ковариации по всему датасету, а $d_{mn}$ - некоторое введенное расстояние между матрицами, чтобы мы могли использовать экспоненциальное ядро, короче нам надо какое-то ядро, которое две матрицы, а не два числа принимает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Весьма убедительно считать расстояние между матрицами просто как l2 метрику между точками в NxN мерном пространстве"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короче надо GPR сделать, у которого точки - матрицы и прогнозируется векторная величина, то есть для матрицы $x_*$ из инпута мы должны получать: $\\mu_* = E[f(x_*)]$ - трехмерное мат ожидание для предсказания и $S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В предположении что компоненты силы независимы, можно использовать Batch Independent Multioutput GP, предсказывая [fx, fy, fz]\n",
    "\n",
    "- Если предсказывать k проекций на все V_i, то компоненты уже зависимые и надо это учитывать и использовать другую модель: MultitaskGPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лосс делаем -mll: минус логарифм правдоподобия: $-log[p(output Y | test X)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = torch.stack([elem[0] for elem in train_data])\n",
    "# train_Y = torch.stack([elem[1] for elem in train_data])\n",
    "\n",
    "# val_X = torch.stack([elem[0] for elem in val_data])\n",
    "# val_Y = torch.stack([elem[1] for elem in val_data])\n",
    "\n",
    "fl = flattener()\n",
    "train_X = fl(torch.stack([elem[0] for elem in train_data]))\n",
    "train_Y = fl(torch.stack([elem[1] for elem in train_data]))\n",
    "\n",
    "val_X = fl(torch.stack([elem[0] for elem in val_data]))\n",
    "val_Y = fl(torch.stack([elem[1] for elem in val_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Про свертки и когда они ожидаемо будут и не будут работать:**\n",
    "\n",
    "    - если мы используем обычный GP, то мы обязаны каждый шаг обучаться на всем train_X - так алгоритм работает, поэтому и сверточная сеть так же должна будет обучаться, по-сути с батч_сайз = дата_сайз, но оно так вычислительно неподъемно или просто не успеет за такое маленькое количество шагов обучиться\n",
    "\n",
    "    - Поэтому стоит использовать алгоритм Stochastic Variational GP Regression, который подразумевает совместимость с torch.DataLoader, когда данных будет очень много, там используется стохастический алгоритм, позволяющий на батче обновлять параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependentOutputsMultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    '''\n",
    "\n",
    "    Class for multi output GPregression with independent components of output,\n",
    "    formally we are training output_size GP models\n",
    "\n",
    "    feature_extractor: torch network that consists only of convolutions (fully convolutional net)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, train_x, train_y, likelihood, output_size=3, feature_extractor=None):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([output_size]))     # batch_shape позволяет нам для каждой модели отдельные параметры сделать\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([output_size])),\n",
    "        )\n",
    "\n",
    "        self.feature_extractor = flattener()\n",
    "        if feature_extractor:\n",
    "            self.feature_extractor = feature_extractor\n",
    "\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'{x.size()}')\n",
    "\n",
    "        convoluted_n_flattened_x = self.feature_extractor(x)   # flattening\n",
    "        convoluted_n_flattened_x = self.scale_to_bounds(convoluted_n_flattened_x)\n",
    "\n",
    "        mean_x = self.mean_module(convoluted_n_flattened_x)\n",
    "        covar_x = self.covar_module(convoluted_n_flattened_x)\n",
    "\n",
    "        # print(f'Сайз выпрямленного:  {convoluted_n_flattened_x.size()} \\n Сам выпрямленный: {convoluted_n_flattened_x}')\n",
    "\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\n",
    "            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinusLogLikelihoodLoss:\n",
    "    def __init__(self, likelihood, model):\n",
    "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    def __call__(self, model_output, true_target):\n",
    "        '''\n",
    "\n",
    "        model_output: what model(train_x) returns, mll uses likelihood by itself\n",
    "\n",
    "        returns -mll(output, target)\n",
    "\n",
    "        '''\n",
    "        return -self.mll(model_output, true_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_train(likelihood, model, optimizer, loss_obj, training_iterations: int, train_X, train_Y, print_step=1, scheduler=None):\n",
    "    '''\n",
    "\n",
    "    loss_obj should be an object of a class, which has __call__ method\n",
    "\n",
    "    to have a clear perspective: on a stochastic network training I used around 2500 iterations\n",
    "\n",
    "    returns history of MSE and loss\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    # scaler = amp.GradScaler()\n",
    "    \n",
    "    # Здесь нам не надо running_loss и running_MSE, потому что подаем сразу весь датасета в типе non-stochastic GP\n",
    "\n",
    "    # Здесь реально обучаются параметры GPR, поскольку некоторая параметрическая часть у GPR все-таки присутствует\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train_X)\n",
    "\n",
    "        loss = loss_obj(output, train_Y)\n",
    "        loss.backward()\n",
    "\n",
    "        predictions = likelihood(model(train_X))\n",
    "        mean = predictions.mean\n",
    "        lower, upper = predictions.confidence_region()\n",
    "\n",
    "        train_MSE = F.mse_loss(input=mean, target=train_Y, reduction='mean').item()\n",
    "\n",
    "        print(f'Iter: {i + 1}, train_MSE = {train_MSE}, train_loss = {loss}') if i % print_step == 0 else 1\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        history['MSE'].append(train_MSE)\n",
    "        history['loss'].append(loss.item())\n",
    "\n",
    "        if scheduler:\n",
    "            # Так как здесь обучение не по мини-батчам, то каждую итерацию обновление\n",
    "            scheduler.step()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно еще в процессе обучения параметров периодически смотреть на качество на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_eval(likelihood, model, optimizer, loss_obj, val_X, val_Y):\n",
    "    '''\n",
    "    \n",
    "    One go dataset evaluation function\n",
    "\n",
    "    '''\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\n",
    "        output = model(val_X)\n",
    "        loss = loss_obj(output, val_Y)\n",
    "\n",
    "    predictions = likelihood(model(val_X))\n",
    "\n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "\n",
    "    val_MSE = F.mse_loss(input=mean, target=val_Y, reduction='mean').item()\n",
    "\n",
    "    print(f'val_MSE = {val_MSE}, val_loss = {loss.item()}')\n",
    "\n",
    "    return mean, lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(LargeFeatureExtractor, self).__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(CFG.K * CFG.K, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))\n",
    "        self.add_module('relu2', torch.nn.ReLU())\n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
    "\n",
    "model = IndependentOutputsMultitaskGPModel(train_X, train_Y, likelihood, feature_extractor=LargeFeatureExtractor())\n",
    "\n",
    "if likelihood.num_tasks != model.output_size:\n",
    "    raise Exception('Different output dimensions for model and likelihood')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=0.03)\n",
    "\n",
    "loss_obj = MinusLogLikelihoodLoss(likelihood=likelihood, model=model)\n",
    "\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, train_MSE = 0.27721360325813293, train_loss = 1.1862082481384277\n",
      "Iter: 6, train_MSE = 0.27789610624313354, train_loss = 1.112740397453308\n",
      "Iter: 11, train_MSE = 0.2778192162513733, train_loss = 1.0416325330734253\n",
      "Iter: 16, train_MSE = 0.27731454372406006, train_loss = 0.9718726873397827\n",
      "Iter: 21, train_MSE = 0.2776170074939728, train_loss = 0.9125633835792542\n",
      "Iter: 26, train_MSE = 0.27727746963500977, train_loss = 0.8617236018180847\n",
      "Iter: 31, train_MSE = 0.27739498019218445, train_loss = 0.8183579444885254\n",
      "Iter: 36, train_MSE = 0.2773369550704956, train_loss = 0.797179639339447\n",
      "Iter: 41, train_MSE = 0.27786144614219666, train_loss = 0.7822433114051819\n",
      "Iter: 46, train_MSE = 0.27724042534828186, train_loss = 0.790104329586029\n",
      "Iter: 51, train_MSE = 0.27725598216056824, train_loss = 0.7945685982704163\n",
      "Iter: 56, train_MSE = 0.27791985869407654, train_loss = 0.7946692705154419\n",
      "Iter: 61, train_MSE = 0.2773755192756653, train_loss = 0.7972681522369385\n",
      "Iter: 66, train_MSE = 0.27778491377830505, train_loss = 0.8009983897209167\n",
      "Iter: 71, train_MSE = 0.2773822844028473, train_loss = 0.811682939529419\n",
      "Iter: 76, train_MSE = 0.2775300443172455, train_loss = 0.8117003440856934\n",
      "Iter: 81, train_MSE = 0.2772170603275299, train_loss = 0.812652051448822\n",
      "Iter: 86, train_MSE = 0.27733665704727173, train_loss = 0.8140323162078857\n",
      "Iter: 91, train_MSE = 0.27720165252685547, train_loss = 0.81524658203125\n",
      "Iter: 96, train_MSE = 0.2772681713104248, train_loss = 0.8162217140197754\n"
     ]
    }
   ],
   "source": [
    "train_history = GP_train(\n",
    "    likelihood=likelihood,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=None,\n",
    "    loss_obj=loss_obj,\n",
    "\n",
    "    training_iterations=100,\n",
    "\n",
    "    train_X=train_X,\n",
    "    train_Y=train_Y,\n",
    "\n",
    "    print_step=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([616, 4])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1248, 4])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_MSE = 0.5699175596237183, val_loss = 1.1506420373916626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0004, 0.0080, 0.0046],\n",
       "         [0.0004, 0.0080, 0.0046],\n",
       "         [0.0004, 0.0080, 0.0046],\n",
       "         ...,\n",
       "         [0.0004, 0.0080, 0.0046],\n",
       "         [0.0004, 0.0080, 0.0046],\n",
       "         [0.0004, 0.0080, 0.0046]], grad_fn=<ViewBackward0>),\n",
       " tensor([[-1.3782, -1.3033, -1.2259],\n",
       "         [-1.3782, -1.3033, -1.2259],\n",
       "         [-1.3782, -1.3033, -1.2259],\n",
       "         ...,\n",
       "         [-1.3782, -1.3033, -1.2259],\n",
       "         [-1.3782, -1.3033, -1.2259],\n",
       "         [-1.3782, -1.3033, -1.2259]], grad_fn=<SubBackward0>),\n",
       " tensor([[1.3789, 1.3194, 1.2351],\n",
       "         [1.3789, 1.3194, 1.2351],\n",
       "         [1.3789, 1.3194, 1.2351],\n",
       "         ...,\n",
       "         [1.3789, 1.3194, 1.2351],\n",
       "         [1.3789, 1.3194, 1.2351],\n",
       "         [1.3789, 1.3194, 1.2351]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GP_eval(\n",
    "    likelihood=likelihood,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_obj=loss_obj,\n",
    "    val_X=val_X,\n",
    "    val_Y=val_Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Stochastic Variational GP Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пока мои выводы / результаты: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про сетки:\n",
    "    - Поскольку в датасете огромное количество сил очень маленькие - модель не в состоянии научиться определять болшьие силы, надо какой-то кастомный лосс придумывать, учитывающий это\n",
    "\n",
    "    - Пока по какой-то причине сетка просто выдает одинаковый аутпут на весь батч на большом количестве частиц (и со свертками и без, и при большом и при маленьком K)\n",
    "\n",
    "    - Для 2 частиц с K = 2 на одной сетке получилось val_MSE = 0.75\n",
    "\n",
    "    - Для 50 частиц с K = 25 вообще ничего не вышло, с K = 5 пока тоже\n",
    "\n",
    "Поэтому я пока отложу идею с 3 сетками и попробую покрутить GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про GP:\n",
    "    - на 50 частицах пока оно не учится...\n",
    "\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler=None):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum').item()\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_MSE = running_MSE / processed_data\n",
    "    \n",
    "    return train_loss, train_MSE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8b603c973ef7f83aae64b632e2e67529bc0c014d258c607b969039a8c89a028"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
