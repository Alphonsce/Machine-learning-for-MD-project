{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Run on python 3.6</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы используют multi output GPR, настраивая гиперпараметры $\\sigma_{cov}$ и $\\sigma_{err}$ (можно однозначно их выразить через гиперпараметры из того же sklearn: $l$ и $\\sigma$)\n",
    "\n",
    "GPR - непараметрический метод, суть в том, что мы делаем предположение о виде матрицы корреляции признаков для известных данных. (но можно добавлять некоторые параметры в ядро и их градиентными методами \"обучать\", потому что все что мы делаем - перемножаем матрицы и используем элементарные функции)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моделирование в хотя бы немного более сложном случае буду писать на Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры:\n",
    "\n",
    "1)k: Количество элементов в массивах r_cut и p для каждого атома\n",
    "\n",
    "2)$r_{cut}(i)_j$, i=1..k, j=1..N: векторы r_cut для j атома тоже параметр\n",
    "\n",
    "3)$p_(i)_j$, i=1..k, j=1..N: векторы p для j атома тоже параметр\n",
    "\n",
    "4)N_neighbours for summation for IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В GPyTorch есть имплементация многоразмерного регрессора: https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/index.html#multi-output-vector-valued-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- **Зачем предсказывать именно K-мерный вектор силы:** \n",
    "    - В системе из 3+ частиц гантелька из двух частиц может вращаться, тогда матрица признаков не изменяется у частиц из этой гантельки, а 3Д сила изменяется, но любое отображение может выдавать только 1 значение для 1 аргумента, то есть мы банально сможем выдавать только одну 3Д силу в таком случае,\n",
    "    однако если мы предсказываем К-мерный вектор, то он все равно будет только 1 выдаваться для частицы из этой вращающейся гантельки, но матрица А при этом будет разной в каждом состоянии и сможем получать разные 3Д векторы силы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Пока что все размерности предполагаются в системе LJ, потому что пока пытаюсь это зафитить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данный момент при вычислении псевдообратной матрицы очень большая ошибка получается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from numba import jit, njit, vectorize\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.linalg import norm as norm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''\n",
    "    \n",
    "    Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.\n",
    "\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    '''\n",
    "\n",
    "    All hyperparameters are here\n",
    "\n",
    "    '''\n",
    "\n",
    "    N = 2     # число атомов\n",
    "    K = 5     # можно называть это разрешением...чем число больше, тем больше размеры матрицы для атомов, фактически это число элементов в наборах p и r_cut\n",
    "\n",
    "    L = L = 2 * N ** (1 / 3) # размер одной клетки при моделировании\n",
    "\n",
    "    r_cut = np.random.uniform(low=5, high=10, size=K).copy()\n",
    "    p = np.random.uniform(low=1, high=3, size=K).copy()\n",
    "    N_neig= N - 1 if N != 2 else 1\n",
    "\n",
    "    # train_bs = 8\n",
    "    # val_bs = 16\n",
    "    batch_size = 64\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    f_threshold = 10    # Если сила по какой-то координате превышает это значение, то строчка исключается, совсем маленьких по модулю сил быть не должно, если что при генерации просто r_cut поменьше надо делать\n",
    "    coord_threshold = 2 * L     # Если вдруг очень большие расстояния, то надо выкидывать\n",
    "    #\n",
    "    output_size = K     # Размерность аутпута модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p: [1.23475109 2.36993749 1.87522212 2.11245865 1.73416064], r_cut: [9.35062068 7.91138464 6.3941947  5.92955616 7.05550064]'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'p: {CFG.p}, r_cut: {CFG.r_cut}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется два .csv файла:\n",
    "\n",
    "1)\n",
    "| Id(time) | 1_x | 1_y | 1_z | ... | N_z |\n",
    "|------|-----|-----|-----|-----|-----|\n",
    "|      |     |     |     |     |     |\n",
    "|      |     |     |     |     |     |\n",
    "2)\n",
    "| Id(time) | f_1_x | f_1_y | f_1_z | ... | f_N_z |\n",
    "|------|-----|-----|-----|-----|-----|\n",
    "|      |     |     |     |     |     |\n",
    "|      |     |     |     |     |     |\n",
    "\n",
    "Одна строчка отсюда превращается в N матриц (на каждый атом) с N векторами сил\n",
    "\n",
    "В идеале сделать БДху из двух сущностей: сила и координата, где полями будут их проекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_coords(coords_file_path = None, forces_file_path = None):\n",
    "    '''\n",
    "    just makes df from .csvs with coords and forces\n",
    "    '''\n",
    "    coords = pd.read_csv(coords_file_path)\n",
    "\n",
    "    forces = pd.read_csv(forces_file_path)\n",
    "\n",
    "    if CFG.N != int(coords.columns[-1][:-1]) + 1:\n",
    "        raise Exception('Constant N is not equal to amount of particles in .csv')\n",
    "\n",
    "    return pd.merge(left=coords, right=forces, on='t').drop('t', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 индекс - 1 отн 2\n",
    "\n",
    "$$\n",
    "\\vec{r_1} = \\vec{r_2} + \\vec{r}_{12}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{r}_{12} = \\vec{r_1} - \\vec{r}_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_positions(row, atom_number):\n",
    "    '''\n",
    "    This function processes one row of csv into something that we can work with\n",
    "\n",
    "    Returns np.array matrix that consists of relative positions vectors for passed atom_number to every other atom\n",
    "    and then we can chose only closest N_neighbours in the next functions\n",
    "    \n",
    "    row: df.iloc[row] - typeof(row): pd.Series\n",
    "    \n",
    "    returns: Rel_matrix, f_vec\n",
    "    '''\n",
    "\n",
    "    s_coord = pd.Series(dtype=float)\n",
    "    other_atom_numbers = [i for i in range(CFG.N) if i != atom_number]\n",
    "\n",
    "    for other_numb in other_atom_numbers:\n",
    "        index = str(atom_number) + str(other_numb)\n",
    "        for axis in ['x', 'y', 'z']:\n",
    "            s_coord[index + axis] = row[str(atom_number) + axis] - row[str(other_numb) + axis]\n",
    "\n",
    "    # we need force vector only for atom_number:\n",
    "    force_vec = []\n",
    "    for f_axis in ['f_x', 'f_y', 'f_z']:\n",
    "        force_vec.append(row[str(atom_number) + f_axis])\n",
    "\n",
    "    Rel_matrix = []\n",
    "    cur_vector = []\n",
    "\n",
    "    for (i, elem) in enumerate(s_coord.values):\n",
    "        if i % 3 == 0 and i != 0:\n",
    "            Rel_matrix.append(cur_vector)\n",
    "            cur_vector = []\n",
    "\n",
    "        cur_vector.append(elem)\n",
    "    Rel_matrix.append(cur_vector)\n",
    "\n",
    "    return np.array(Rel_matrix), np.array(force_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def make_one_vec_transformed(vec, vec_norm, r_cut_i, p_i):\n",
    "    '''\n",
    "    vec: np.array - normalized vector\n",
    "    norm: its norm\n",
    "    r_cut_i: i-th component of\n",
    "    '''\n",
    "    return vec * np.exp(\n",
    "        -np.power((vec_norm / r_cut_i), p_i)\n",
    "        )\n",
    "\n",
    "make_matrix_transformed = np.vectorize(make_one_vec_transformed)\n",
    "\n",
    "def create_V_i(i, normalized_m, norms, r_cut=CFG.r_cut, p=CFG.p):\n",
    "    '''\n",
    "    normalized_m: matrix of relative distances, where rows - normalized vectors\n",
    "    i: i-th component of r_cut and p, i in range 1..K (or in 0..K-1 in code)\n",
    "    '''\n",
    "    transf_vecs = make_matrix_transformed(normalized_m, norms[:, np.newaxis], r_cut[i], p[i])\n",
    "\n",
    "    return np.sum(transf_vecs, axis=0)\n",
    "\n",
    "# @njit(parallel=True)\n",
    "def create_V(normalized_m, norms, K=CFG.K):\n",
    "    '''\n",
    "    creates V\n",
    "    '''\n",
    "    V = []\n",
    "    for i in range(K):\n",
    "        V.append(\n",
    "            create_V_i(i, normalized_m, norms)\n",
    "        )\n",
    "\n",
    "    return np.stack(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit(\n",
    "#     # parallel=True,\n",
    "#     # fastmath=True\n",
    "#     )\n",
    "def _calculate_matrix_for_atom(relative_distances, r_cut=CFG.r_cut, p=CFG.p, N_neig=CFG.N_neig, K=CFG.K):\n",
    "    '''\n",
    "\n",
    "    relative_distances: np.array matrix of relative distance vectors\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Only closest N_neig are counting:\n",
    "    indexlist = np.argsort(norm(relative_distances, axis=1))\n",
    "\n",
    "    relative_distances = relative_distances[indexlist[len(relative_distances) - N_neig:]]\n",
    "\n",
    "    norms = norm(relative_distances, axis=-1)\n",
    "\n",
    "    normalized_rel_distances = relative_distances / norms[:, np.newaxis]\n",
    "\n",
    "    V = create_V(normalized_rel_distances, norms)\n",
    "\n",
    "    if np.inf in V / norm(V, axis=-1)[:, np.newaxis] or np.nan in V / norm(V, axis=-1)[:, np.newaxis]:\n",
    "        print(f'V:\\n {V}\\n norms:\\n {norm(V, axis=-1)[:, np.newaxis]}\\n normed_V:\\n {V / norm(V, axis=-1)[:, np.newaxis]}')\n",
    "        print(f'ABOUT RELATIVE DISTANCES:\\n rel_dists:\\n {relative_distances}\\n norms:\\n{norms}\\n normalized_rel_dists:\\n {normalized_rel_distances}')\n",
    "\n",
    "    A = V / norm(V, axis=-1)[:, np.newaxis]\n",
    "\n",
    "    X = V @ A.T\n",
    "\n",
    "    return X, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_for_atom(row = None, atom_number = None, N_neig=CFG.N_neig):\n",
    "    '''\n",
    "\n",
    "    This function will create X matrix for passed atom with\n",
    "    arrays of r_cut and p of length k\n",
    "\n",
    "    It is a wrapper for _get_relative_positions and _calculate_matrix_for_atom, so I can speed up matrix calculations\n",
    "    with numba for _calculate_matrix_for_atom\n",
    "\n",
    "    atom_number: a number of atom that we are passing\n",
    "    row: one row from df_with_coords, i.e. df.iloc[index_of_row]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # creating row of relative coordinates for concrete atom:\n",
    "    relative_distances, f_vec = _get_relative_positions(row=row, atom_number=atom_number)\n",
    "    X, A = _calculate_matrix_for_atom(relative_distances=relative_distances, N_neig=N_neig)\n",
    "    \n",
    "    return X, f_vec, A\n",
    "\n",
    "# %timeit get_matrix_for_atom(row=df.iloc[0], atom_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**У нас будет train и val выборки, все-таки выборку, для который известен таргет принято называть validation, на которой мы качество оцениваем, а test это все-таки выборка, для который неизвестны таргеты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df: pd.DataFrame, f_threshold = CFG.f_threshold, coord_threshold=CFG.coord_threshold):\n",
    "    '''\n",
    "\n",
    "    Убирает строчки с аномально большими силами из df\n",
    "\n",
    "    '''\n",
    "\n",
    "    indexes_for_deletion = set()\n",
    "\n",
    "    for numb in range(CFG.N):\n",
    "        for coord in ['f_x', 'f_y', 'f_z']:\n",
    "\n",
    "            indexes_for_deletion = indexes_for_deletion.union(\n",
    "                set(df[abs(df[str(numb) + coord]) > f_threshold].index)\n",
    "            )\n",
    "\n",
    "        for coord in ['x', 'y', 'z']:\n",
    "            indexes_for_deletion = indexes_for_deletion.union(\n",
    "                set(df[abs(df[str(numb) + coord]) > coord_threshold].index)\n",
    "            )\n",
    "\n",
    "    return df.drop(list(indexes_for_deletion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_pinv(A):\n",
    "    '''\n",
    "\n",
    "    returns pseudoinverse matrix for input\n",
    "\n",
    "    '''\n",
    "    return np.linalg.pinv(A)\n",
    "\n",
    "def get_projections(vec_to_project, mat_of_directions):\n",
    "    '''\n",
    "\n",
    "    returns projection of vec_to_project on every vector from mat_of_directions\n",
    "\n",
    "    '''\n",
    "    return (mat_of_directions @ vec_to_project) / norm(mat_of_directions, axis=-1)\n",
    "\n",
    "def create_tensor_dataset(\n",
    "    coords_file_path = 'coords.csv', forces_file_path = 'forces.csv', step=1, transform=transforms.ToTensor(), length=None,\n",
    "    f_threshold=CFG.f_threshold,\n",
    "    coord_threshold=CFG.coord_threshold,\n",
    "    ):\n",
    "    '''\n",
    "\n",
    "    Примитивная версия датасета, просто все будет хранить в одном списке...\n",
    "\n",
    "    Эта функция - wrapper на все выше написанные функции, она по переданным путям к .csv\n",
    "    возвращает тензор из матриц для каждого атома в каждой строчке и тензор из векторов сил\n",
    "\n",
    "    ИНогда есть смысл делать побольше шаг между соседними строчками, поскольку если есть почти одинаковые матрицы, то\n",
    "    это по-сути линейная зависимость и модель тогда надо сильнее регулизировать\n",
    "\n",
    "    transform: преобразование к X части датасета, в основном для нормализации нужно, хотя о нормализации надо еще подумать и будет ли тогда наше МНК через матрицу A+ работать\n",
    "\n",
    "    step: через сколько строчек шагать при чтении csv в датасет, чтобы уж совсем одинаковых не было\n",
    "\n",
    "    Возвращает: list of (X, k_dim_f, A_pinv, F_3D)\n",
    "\n",
    "    '''\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    df = create_df_with_coords(coords_file_path=coords_file_path, forces_file_path=forces_file_path)\n",
    "    if length:\n",
    "        df = df.loc[range(length)]\n",
    "\n",
    "    # Сюда будет вставлена чистка df от больших сил\n",
    "    df = clean_df(df, f_threshold=f_threshold, coord_threshold=coord_threshold)\n",
    "\n",
    "    row_indexes = [i for i in range(0, len(df.index), step)]\n",
    "\n",
    "    for atom_number in range(CFG.N):\n",
    "        for index in tqdm(row_indexes, desc=f'Progress for atom {atom_number}'):\n",
    "            row = df.iloc[index]\n",
    "            x, F_3D, A = get_matrix_for_atom(row=row, atom_number=atom_number)\n",
    "            \n",
    "            if transform:\n",
    "                x = transform(x)\n",
    "            else:\n",
    "                x = torch.tensor(x)\n",
    "            x = x.to(torch.float)\n",
    "\n",
    "            k_dim_f = get_projections(vec_to_project=F_3D, mat_of_directions=A)\n",
    "\n",
    "            dataset.append(\n",
    "                (x, torch.tensor(k_dim_f, dtype=torch.float), torch.tensor(get_pinv(A), dtype=torch.float), torch.tensor(F_3D, dtype=torch.float))\n",
    "                )\n",
    "            \n",
    "            # В дальнейшем для других моделей может иметь смысл хранить и возвращать тут (x, f, A), где A - соответствующая матрица для X\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Когда только начинаю работать с датасетом надо один раз на трейне посчитать std и mean, чтобы нормализовать можно было\n",
    "\n",
    "mean = 1.1201671361923218\n",
    "std = 0.3449265956878662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все-таки у нас тут не картинки будут, поэтому я попробую сначала даже без нормализации, нормализовать надо 1 канал, если в терминах картинки рассуждать\n",
    "\n",
    "transform = transforms.Compose([                                    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress for atom 0: 100%|██████████| 468/468 [00:00<00:00, 469.32it/s]\n",
      "Progress for atom 1: 100%|██████████| 468/468 [00:00<00:00, 583.43it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = create_tensor_dataset(coords_file_path='coords2.csv', forces_file_path='forces2.csv', step=100)\n",
    "\n",
    "# Uncomment, when calculated and changed mean and std:\n",
    "\n",
    "# dataset = create_tensor_dataset('coords2.csv', 'forces2.csv', step=40, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8131, 0.8131, 0.8131, 0.8131, 0.8131],\n",
       "          [0.9303, 0.9303, 0.9303, 0.9303, 0.9303],\n",
       "          [0.8300, 0.8300, 0.8300, 0.8300, 0.8300],\n",
       "          [0.8380, 0.8380, 0.8380, 0.8380, 0.8380],\n",
       "          [0.8367, 0.8367, 0.8367, 0.8367, 0.8367]]]),\n",
       " tensor([-0.0289, -0.0289, -0.0289, -0.0289, -0.0289]),\n",
       " tensor([[-0.0782, -0.0782, -0.0782, -0.0782, -0.0782],\n",
       "         [-0.0401, -0.0401, -0.0401, -0.0401, -0.0401],\n",
       "         [ 0.1796,  0.1796,  0.1796,  0.1796,  0.1796]]),\n",
       " tensor([ 0.0113,  0.0058, -0.0259]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0289, -0.0289, -0.0289, -0.0289, -0.0289]),\n",
       " tensor([ 0.0113,  0.0058, -0.0259]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dataset[400]\n",
    "pinvA = t[2]\n",
    "f = t[1]\n",
    "F_3d = t[3]\n",
    "\n",
    "f, F_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока никакие параметры особо не надо настраивать, поэтому и кросс валидацию не буду делать пока что, затем ее можно сделать, передавая в функцию create_dataloaders еще один параметр - фолд, на котором трейн, предварительно поделив на фолды датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если просто брать в качестве трейна другие строчки из одной генерации, то можно не отследить переобучения, стоит пробовать тестить на датасете, который отдельно сгенерирован с таким же числом частиц, который модель еще вообще не видела"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 5]), tensor([[[0.8539, 0.8539, 0.8539, 0.8539, 0.8539],\n",
       "          [0.9579, 0.9579, 0.9579, 0.9579, 0.9579],\n",
       "          [0.8837, 0.8837, 0.8837, 0.8837, 0.8837],\n",
       "          [0.8947, 0.8947, 0.8947, 0.8947, 0.8947],\n",
       "          [0.8852, 0.8852, 0.8852, 0.8852, 0.8852]]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.33, random_state=42)\n",
    "\n",
    "train_data[400][0].size(), train_data[400][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Код для выяснения mean и std у трейновой выборки и для проверки уже после нормализации: (по ненормализованному датасету делается)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.8781628012657166, std = 0.06477992236614227\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std_for_train_X(train_data):\n",
    "    train_X = torch.cat([row[0] for row in train_data])\n",
    "\n",
    "    print(\n",
    "        f'mean = {torch.mean(train_X)}, std = {torch.std(train_X)}'\n",
    "    )\n",
    "\n",
    "get_mean_and_std_for_train_X(train_data=train_data) # тупо проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Когда молекул уже будет много как хранить данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта клетка нужна будет, когда молекул будет много (N > 100, K порядка 100)\n",
    "\n",
    "def create_df_with_paths(df_coords: pd.DataFrame, first_folder = 'Atom_matrices'):\n",
    "    '''\n",
    "\n",
    "    Пока эта функция не нужна, но в будущем за счет нее как раз будет работать PathBasedDataset\n",
    "\n",
    "    gets df, returns df with paths to torch matrices for each atom for different times,\n",
    "    basically this function will call get_matrix_for_atom a lot of times\n",
    "\n",
    "    output: pd.DataFrame that orignated from this:\n",
    "    \n",
    "    | Index | 1_atom_X_path                     | ... | N_atom_X_path                     |\n",
    "    |-------|-----------------------------------|-----|-----------------------------------|\n",
    "    | 1     | ./atom_matrices/index1/atom1.tb   |     | ./atom_matrices/index1/atomN.tb   |\n",
    "    | ...   |                                   |     |                                   |\n",
    "    | 30k   | ./atom_matrices/index30k/atom1.tb |     | ./atom_matrices/index30k/atomN.tb |\n",
    "    \n",
    "    but eventually will look like this:\n",
    "\n",
    "    | Index   | atom_X_path                       |\n",
    "    |---------|-----------------------------------|\n",
    "    | 1       | ./atom_matrices/index1/atom1.tb   |\n",
    "    | ...     | ...                               |\n",
    "    | 30k * N | ./atom_matrices/index30k/atomN.tb |\n",
    "\n",
    "    '''\n",
    "    row_numbers = df_coords.index\n",
    "\n",
    "    df_paths = pd.DataFrame(\n",
    "        {\n",
    "            'path': []\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pass\n",
    "\n",
    "class PathBasedDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "\n",
    "    Это будет класс датасета из торча для большого числа молекул, если молекул будет очень много, то надо будет уже хранить все матрицы X не в оперативной памяти\n",
    "\n",
    "    При создании экземпляра будет передаваться pd.Dataframe, который\n",
    "    состоит из трех колонок - проекций вектора силы и еще одной колонки - путь к файлу, где лежит как-то заэнкоженная\n",
    "    матрица для данного атома, и так для каждого атома (я проверил, что запись и чтение при помощи torch.save и torch.load для тензоров очень быстрое)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, df, transforms=None, mode='train'):\n",
    "        self.df = df    # it will be dataframe with coordinates and forces of all atoms\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = 1   # it will be a matrix KxK for each atom\n",
    "        y = 1   # it will be a force vector with shape: (3)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, train_bs=CFG.batch_size, val_bs=CFG.batch_size, fold=None):\n",
    "    '''\n",
    "\n",
    "    Returns train_loader, val_loader\n",
    "\n",
    "    fold: will be used in cross validation, when I will implement it\n",
    "\n",
    "    '''\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=val_bs, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_dataloaders(train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 5, 5])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].size()  # [batch_size, Channels, Height, Width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)Многомерный аутпут:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще постоянный множитель - это не особо важно, но просто при оценке качества модели возникнут определенные трудности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultuOutputMSELoss(nn.MSELoss):\n",
    "    '''\n",
    "\n",
    "    Custom loss that calculates average over batch loss for multidim MSE - sum of MSE for components\n",
    "\n",
    "    Example:\n",
    "    |\n",
    "    |    Loss = MultuOutputMSELoss()\n",
    "    |\n",
    "    |    a = torch.ones((8, 3))      # it is batch of 8 vectors of size 3\n",
    "    |    b = torch.zeros((8, 3))\n",
    "    |\n",
    "    |    Loss(a, b, batch_size=8) -> 3\n",
    "\n",
    "    '''\n",
    "\n",
    "    def forward(self, input, target, batch_size=CFG.batch_size):\n",
    "        '''\n",
    "        оно при reduction='mean' делит на произведение всех размерностей\n",
    "        '''\n",
    "        # при очень большом размере батча последние батчи будут например размера 128 вместо 256, поэтому просто умножать на батч сайз неправильно, могут быть другого размера\n",
    "\n",
    "        return F.mse_loss(input, target, reduction='sum') / input.size(0)   # или эквивалентно делать reduction='mean' и умножать на input.size()[-1] - length of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNLLLossWithReadyVar(nn.GaussianNLLLoss):\n",
    "    '''\n",
    "\n",
    "    Custom GaussianNLLLoss that does not require passing var into forward\n",
    "\n",
    "    The targets are treated as samples from Gaussian distributions, so var is calculated on full train data, assuming it was taken from the same distribution\n",
    "\n",
    "    '''\n",
    "    def __init__(self, full=False, eps=1e-06, reduction='sum'):\n",
    "        super().__init__(full=full, eps=eps, reduction=reduction)\n",
    "        self.__var_vector = torch.std(torch.stack([elem[1] for elem in train_data]), dim=0)\n",
    "        # self.__var = torch.ones(200, 10, requires_grad=True)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # неважно, что оно может делать mean еще по размерностям, это всего лишь домножение на константу\n",
    "        var = torch.stack([self.__var_vector] * input.size(0)).to(CFG.device)\n",
    "\n",
    "        return F.gaussian_nll_loss(input=input, target=target, var=var, reduction=self.reduction) / input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flattener(torch.nn.Module):\n",
    "    '''\n",
    "\n",
    "    Module that flattens the input\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()    \n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNet(nn.Module):\n",
    "    '''\n",
    "\n",
    "    Класс одиночной нейронной сети\n",
    "\n",
    "    '''\n",
    "    def __init__(self, output_size, convolution=None, activation=nn.ReLU(), flattened_size=CFG.K * CFG.K):\n",
    "        '''\n",
    "        \n",
    "        FC_type: тип полносвязных слоев: 'regular' / 'simple\n",
    "\n",
    "        convolution: сверточная часть сети\n",
    "\n",
    "        '''\n",
    "        super().__init__()\n",
    "        if convolution and flattened_size == CFG.K * CFG.K:\n",
    "            raise Exception('PASSED CONV LAYERS, BUT DID NOT PASS FLATTENED SIZE')\n",
    "\n",
    "        self.conv_layers = flattener()\n",
    "\n",
    "        if convolution:\n",
    "            self.conv_layers = convolution\n",
    "\n",
    "        # self.FC = nn.Sequential(\n",
    "        #     nn.Linear(flattened_size, 1024),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 1024),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 1024),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 1024),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 1024),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 512),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.Linear(512, 256),\n",
    "\n",
    "        #     nn.Linear(256, 128),\n",
    "        #     activation,\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.Linear(128, output_size)\n",
    "        # )\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 1024),\n",
    "            activation,\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(1024),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            activation,\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            activation,\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "        # self.FC = nn.Sequential(\n",
    "        #     nn.Linear(flattened_size, 128),\n",
    "        #     activation,\n",
    "        #     # nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.Linear(128, output_size),\n",
    "        # )\n",
    "\n",
    "        # self.FC = nn.Linear(flattened_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x - is batch of matrices KxK\n",
    "\n",
    "        # Здесь происходят какие-то там свертки, пуллинги и тп..\n",
    "\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики буду использовать сумму MSE по компонентам, лоссы можно разные пробовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    В данной версии: (X, f_k_dim, A_pinv, F_3D)\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_data = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    for inputs, labels, pinv_As, labels_3D in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "        pinv_As = pinv_As.to(CFG.device).detach()   # здесь можно не делать detach и обучать матрицу A\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        outputs_3D = torch.bmm(pinv_As, torch.unsqueeze(outputs.to(torch.float), 2)).to(torch.device(\"cpu\"))    # используются для вычисления MSE метрики уже на 3D векторах силы\n",
    "        outputs_3D = torch.squeeze(outputs_3D, -1)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update() \n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)    # при очень большом размере батча последние два батча будут например размера 128 вместо 256, поэтому просто умножать на батч сайз неправильно, могут быть другого размера\n",
    "        running_MSE += F.mse_loss(input=outputs_3D, target=labels_3D, reduction='sum').item()\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    # print(outputs)\n",
    "    train_loss = running_loss / processed_data\n",
    "    train_MSE = running_MSE / processed_data\n",
    "    \n",
    "    return train_loss, train_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    '''\n",
    "\n",
    "    Одна эпоха по val выборке\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels, pinv_As, labels_3D in val_loader:\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "        pinv_As = pinv_As.to(CFG.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        outputs_3D = torch.bmm(pinv_As, torch.unsqueeze(outputs, 2)).to(torch.device(\"cpu\")) \n",
    "        outputs_3D = torch.squeeze(outputs_3D, -1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs_3D, target=labels_3D, reduction='sum')\n",
    "        processed_size += inputs.size(0)\n",
    "\n",
    "    # print(f' outputs:\\n{outputs}, \\n labels: \\n {labels}')\n",
    "    \n",
    "    val_loss = running_loss / processed_size\n",
    "    val_MSE = running_MSE.double().item() / processed_size\n",
    "\n",
    "    return val_loss, val_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optimizer, scheduler, epochs, scaler=None, criterion=MultuOutputMSELoss()):\n",
    "    '''\n",
    "\n",
    "    Basic option: calculation loss on K-dimensional outputs, but MSE metric on 3D outputs, after the matrix is applied\n",
    "\n",
    "    loss_on_k_projections: calculate loss'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss {v_loss:0.4f} train_MSE {t_mse:0.4f} val_MSE {v_mse:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_MSE = fit_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "            val_loss, val_MSE = eval_epoch(model, val_loader, criterion)\n",
    "            if epoch != 0:\n",
    "                if history[-1][-1] < val_MSE:\n",
    "                    torch.save(model.state_dict(), './model.pth')     # сохраняем модель напрямую в гугл диск \n",
    "            \n",
    "            history.append((train_loss, train_MSE, val_loss, val_MSE))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss, v_loss=val_loss, t_mse=train_MSE, v_mse=val_MSE))\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "__conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(num_features=3),\n",
    "\n",
    "            # nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3),\n",
    "            # activation,\n",
    "            # nn.MaxPool2d(kernel_size=3),\n",
    "            # nn.BatchNorm2d(num_features=8)\n",
    "\n",
    "            flattener()\n",
    ")\n",
    "\n",
    "# Код для проверки длины конкатенированного вектора на вход в FC:\n",
    "\n",
    "# t = next(iter(train_loader))\n",
    "# a = conv_layers(t[0])\n",
    "# a.size()\n",
    "# a.view(a.size(0), -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleNet(\n",
    "    output_size=CFG.output_size,\n",
    "    # activation=nn.Tanh(),\n",
    "    convolution=None,\n",
    "    ).to(CFG.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "\n",
    "# scheduler.step нужно первый раз делать обязательно после optimizer.step, потому что иначе мы просто пропустим первый шаг scheduler\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleNet(\n",
       "  (conv_layers): flattener()\n",
       "  (FC): Sequential(\n",
       "    (0): Linear(in_features=25, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.3, inplace=False)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/30 [00:00<?, ?it/s]/home/alphonse/anaconda3/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "epoch:  13%|█▎        | 4/30 [00:00<00:01, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 5.8968 val_loss 3.0610 train_MSE 2.7792 val_MSE 1.2041\n",
      "\n",
      "Epoch 002 train_loss: 5.6889 val_loss 2.9081 train_MSE 2.7349 val_MSE 1.0988\n",
      "\n",
      "Epoch 003 train_loss: 5.3099 val_loss 3.0593 train_MSE 2.5510 val_MSE 1.1973\n",
      "\n",
      "Epoch 004 train_loss: 5.3049 val_loss 3.0065 train_MSE 2.5650 val_MSE 1.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  27%|██▋       | 8/30 [00:00<00:01, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 005 train_loss: 5.4230 val_loss 2.9623 train_MSE 2.6568 val_MSE 1.1377\n",
      "\n",
      "Epoch 006 train_loss: 5.3100 val_loss 2.9351 train_MSE 2.5988 val_MSE 1.1238\n",
      "\n",
      "Epoch 007 train_loss: 5.4386 val_loss 2.8517 train_MSE 2.6863 val_MSE 1.0685\n",
      "\n",
      "Epoch 008 train_loss: 5.2495 val_loss 2.8864 train_MSE 2.5741 val_MSE 1.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|████      | 12/30 [00:00<00:01, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 009 train_loss: 5.2494 val_loss 2.9155 train_MSE 2.5771 val_MSE 1.1120\n",
      "\n",
      "Epoch 010 train_loss: 5.1947 val_loss 2.8850 train_MSE 2.5469 val_MSE 1.0923\n",
      "\n",
      "Epoch 011 train_loss: 5.2344 val_loss 2.8876 train_MSE 2.5741 val_MSE 1.0940\n",
      "\n",
      "Epoch 012 train_loss: 5.2170 val_loss 2.8781 train_MSE 2.5608 val_MSE 1.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  53%|█████▎    | 16/30 [00:00<00:00, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 013 train_loss: 5.2146 val_loss 2.8907 train_MSE 2.5597 val_MSE 1.0960\n",
      "\n",
      "Epoch 014 train_loss: 5.2678 val_loss 2.8838 train_MSE 2.5944 val_MSE 1.0916\n",
      "\n",
      "Epoch 015 train_loss: 5.2302 val_loss 2.8743 train_MSE 2.5716 val_MSE 1.0852\n",
      "\n",
      "Epoch 016 train_loss: 5.1872 val_loss 2.8743 train_MSE 2.5444 val_MSE 1.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  67%|██████▋   | 20/30 [00:01<00:00, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 017 train_loss: 5.2468 val_loss 2.8599 train_MSE 2.5819 val_MSE 1.0762\n",
      "\n",
      "Epoch 018 train_loss: 5.2430 val_loss 2.8607 train_MSE 2.5810 val_MSE 1.0767\n",
      "\n",
      "Epoch 019 train_loss: 5.2854 val_loss 2.8613 train_MSE 2.6077 val_MSE 1.0770\n",
      "\n",
      "Epoch 020 train_loss: 5.2239 val_loss 2.8781 train_MSE 2.5706 val_MSE 1.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  80%|████████  | 24/30 [00:01<00:00, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 021 train_loss: 5.1555 val_loss 2.8826 train_MSE 2.5238 val_MSE 1.0908\n",
      "\n",
      "Epoch 022 train_loss: 5.2216 val_loss 2.8931 train_MSE 2.5677 val_MSE 1.0975\n",
      "\n",
      "Epoch 023 train_loss: 5.2086 val_loss 2.9000 train_MSE 2.5595 val_MSE 1.1018\n",
      "\n",
      "Epoch 024 train_loss: 5.2559 val_loss 2.8959 train_MSE 2.5894 val_MSE 1.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  93%|█████████▎| 28/30 [00:01<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 025 train_loss: 5.1991 val_loss 2.9046 train_MSE 2.5527 val_MSE 1.1048\n",
      "\n",
      "Epoch 026 train_loss: 5.2175 val_loss 2.9065 train_MSE 2.5645 val_MSE 1.1059\n",
      "\n",
      "Epoch 027 train_loss: 5.1964 val_loss 2.9004 train_MSE 2.5507 val_MSE 1.1022\n",
      "\n",
      "Epoch 028 train_loss: 5.2135 val_loss 2.9089 train_MSE 2.5632 val_MSE 1.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 30/30 [00:01<00:00, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 029 train_loss: 5.2203 val_loss 2.9102 train_MSE 2.5689 val_MSE 1.1081\n",
      "\n",
      "Epoch 030 train_loss: 5.1641 val_loss 2.9106 train_MSE 2.5302 val_MSE 1.1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    train_loader=train_loader, val_loader=val_loader, model=model, optimizer=optimizer,\n",
    "    scheduler=exp_scheduler,\n",
    "    # criterion=nn.MSELoss(),\n",
    "    criterion = GaussianNLLLossWithReadyVar(),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history, figsize=(40, 15)):\n",
    "    '''\n",
    "\n",
    "    history: [(train_loss, train_MSE, val_loss, val_MSE), ...]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # writer = SummaryWriter()\n",
    "    \n",
    "    figure = plt.figure(figsize=figsize)\n",
    "\n",
    "    train_loss = [tup[0] for tup in history]\n",
    "    train_MSE = [tup[1] for tup in history]\n",
    "    val_loss = [tup[2] for tup in history]\n",
    "    val_MSE = [tup[3] for tup in history]\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(history) + 1), train_loss, label='train_loss')\n",
    "    plt.plot(range(1, len(history) + 1), val_loss, label='val_loss')\n",
    "    \n",
    "    plt.title('Losses', fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)     \n",
    "    plt.xticks(np.arange(1, len(history) + 1, 1))\n",
    "    # plt.yticks(np.arange(1, len(history) + 1, 1))\n",
    "    plt.legend(loc='best')\n",
    "    #\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(range(1, len(history) + 1), train_MSE, label='train_MSE')\n",
    "    plt.plot(range(1, len(history) + 1), val_MSE, label='val_MSE')\n",
    "    \n",
    "    plt.title('Metrics', fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)     \n",
    "    plt.xticks(np.arange(1, len(history) + 1, 1))\n",
    "    # plt.yticks(np.arange(1, len(history) + 1, 1))\n",
    "    plt.legend(loc='best', fontsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dc5ed2b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Output_size сеток с одномерным аутпутом (предполагаем независимость всех компонент силы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто обучаю набор сеток на задачу регрессии, в качестве метрики для каждой сетки буду использовать MSE, а итоговая метрика - сумма MSE для каждой сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Просто делаю массив из экземпляров сеток, optim-ов, loss-ов и потом циклом по ним делаю ровно тот же самый вызов history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всем сеткам делаю абсолютно одинаковые гиперпараметры\n",
    "\n",
    "models = [SingleNet(output_size=1) for _ in range(CFG.output_size)]\n",
    "\n",
    "lr = 4e-3\n",
    "betas=(0.9, 0.999)\n",
    "weight_decay=0.1\n",
    "\n",
    "optims = [optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay) for model in models]\n",
    "\n",
    "step_size = 5\n",
    "gamma = 0.1\n",
    "\n",
    "exp_schedulers = [lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) for optimizer in optims]\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое главное при обучении этих моделей - то что у model[ i ] - таргет - это число force[ i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    '''\n",
    "    \n",
    "    Возвращает словарь из history для всех моделей: {1: history, 2: history, ...}\n",
    "\n",
    "    '''\n",
    "\n",
    "    histories = defaultdict(list)\n",
    "\n",
    "    # Надо менять немного цикл обучения, чтобы таргетом для i сетки была i-ая компонента вектора силы\n",
    "\n",
    "    # for i in range(CFG.output_size):\n",
    "    #     histories[str(i)] = train(\n",
    "    #         train_loader=train_loader,\n",
    "    #         val_loader=val_loader,\n",
    "    #         model=model,\n",
    "    #         optimizer=optimizer,\n",
    "    #         scheduler=exp_scheduler,\n",
    "    #         criterion=nn.MSELoss(),\n",
    "    #         epochs=10\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) GPR модель \n",
    "    - (потом можно сюда навалить и сетку в качестве ядра и вообще deep GP юзать, плюс еще feature extractor в виде сверток юзать сначала, если очень большая матрица, но сначала надо обычный сделать)\n",
    "\n",
    "## 3.1) Не стохастический подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html - как обучать модели в gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.gpytorch.ai/en/v1.3.1/examples/04_Variational_and_Approximate_GPs/SVGP_Regression_CUDA.html - как обучать GP по мини батчам, когда данных слишком много"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У авторов $C_{mn}$ - это матрица ковариации по всему датасету, а $d_{mn}$ - некоторое введенное расстояние между матрицами, чтобы мы могли использовать экспоненциальное ядро, короче нам надо какое-то ядро, которое две матрицы, а не два числа принимает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Весьма убедительно считать расстояние между матрицами просто как l2 метрику между точками в NxN мерном пространстве"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короче надо GPR сделать, у которого точки - матрицы и прогнозируется векторная величина, то есть для матрицы $x_*$ из инпута мы должны получать: $\\mu_* = E[f(x_*)]$ - трехмерное мат ожидание для предсказания и $S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В предположении что компоненты силы независимы, можно использовать Batch Independent Multioutput GP, предсказывая [fx, fy, fz]\n",
    "\n",
    "- Если предсказывать k проекций на все V_i, то компоненты уже зависимые и надо это учитывать и использовать другую модель: MultitaskGPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лосс делаем -mll: минус логарифм правдоподобия: $-log[p(output Y | test X)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = torch.stack([elem[0] for elem in train_data])\n",
    "# train_Y = torch.stack([elem[1] for elem in train_data])\n",
    "\n",
    "# val_X = torch.stack([elem[0] for elem in val_data])\n",
    "# val_Y = torch.stack([elem[1] for elem in val_data])\n",
    "\n",
    "fl = flattener()\n",
    "train_X = fl(torch.stack([elem[0] for elem in train_data]))\n",
    "train_Y = torch.stack([elem[1] for elem in train_data])\n",
    "\n",
    "val_X = fl(torch.stack([elem[0] for elem in val_data]))\n",
    "val_Y = torch.stack([elem[1] for elem in val_data])\n",
    "\n",
    "val_Y_3D = torch.stack([elem[3] for elem in val_data])\n",
    "val_Y_pinv_As = torch.stack([elem[2] for elem in val_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Про свертки и когда они ожидаемо будут и не будут работать:**\n",
    "\n",
    "    - если мы используем обычный GP, то мы обязаны каждый шаг обучаться на всем train_X - так алгоритм работает, поэтому и сверточная сеть так же должна будет обучаться, по-сути с батч_сайз = дата_сайз, но оно так вычислительно неподъемно или просто не успеет за такое маленькое количество шагов обучиться\n",
    "\n",
    "    - Поэтому стоит использовать алгоритм Stochastic Variational GP Regression, который подразумевает совместимость с torch.DataLoader, когда данных будет очень много, там используется стохастический алгоритм, позволяющий на батче обновлять параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependentOutputsMultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    '''\n",
    "\n",
    "    Class for multi output GPregression with independent components of output,\n",
    "    formally we are training output_size GP models\n",
    "\n",
    "    feature_extractor: torch network that consists only of convolutions (fully convolutional net)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, train_x, train_y, likelihood, output_size=CFG.K, feature_extractor=None):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([output_size]))     # batch_shape позволяет нам для каждой модели отдельные параметры сделать\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([output_size])),\n",
    "        )\n",
    "\n",
    "        self.feature_extractor = flattener()\n",
    "        if feature_extractor:\n",
    "            self.feature_extractor = feature_extractor\n",
    "\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        convoluted_n_flattened_x = self.feature_extractor(x)   # flattening\n",
    "        convoluted_n_flattened_x = self.scale_to_bounds(convoluted_n_flattened_x)\n",
    "\n",
    "        mean_x = self.mean_module(convoluted_n_flattened_x)\n",
    "        covar_x = self.covar_module(convoluted_n_flattened_x)\n",
    "\n",
    "        # print(f'Сайз выпрямленного:  {convoluted_n_flattened_x.size()} \\n Сам выпрямленный: {convoluted_n_flattened_x}')\n",
    "\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\n",
    "            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinusLogLikelihoodLoss:\n",
    "    '''\n",
    "\n",
    "    Object for computing NLLLoss\n",
    "\n",
    "    '''\n",
    "    def __init__(self, likelihood, model):\n",
    "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    def __call__(self, model_output, true_target):\n",
    "        '''\n",
    "\n",
    "        model_output: what model(train_x) returns, i.e. distribution object, mll uses likelihood by itself\n",
    "\n",
    "        returns -mll(output, target)\n",
    "\n",
    "        '''\n",
    "        return -self.mll(model_output, true_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPRMSELoss:\n",
    "    '''\n",
    "    \n",
    "    object for calculation of MSE loss\n",
    "\n",
    "    '''\n",
    "    def __init__(self, likelihood):\n",
    "        self.vanilla_MSE = MultuOutputMSELoss()\n",
    "        self.likelihood = likelihood    # самописанные объекты изменяемые, поэтому этот имеет тот же id, что и глобальный likelihood\n",
    "\n",
    "    def __call__(self, model_output, true_target):\n",
    "        '''\n",
    "\n",
    "        model_output: what model(train_x) returns, i.e. distribution object\n",
    "\n",
    "        '''\n",
    "        print(id(self.likelihood))\n",
    "        mean_of_output = self.likelihood(model_output).mean\n",
    "\n",
    "        return self.vanilla_MSE(mean_of_output, true_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_train(likelihood, model, optimizer, loss_obj, training_iterations: int, train_X, train_Y, print_step=1, scheduler=None):\n",
    "    '''\n",
    "\n",
    "    loss_obj should be an object of a class, which has __call__ method\n",
    "\n",
    "    to have a clear perspective: on a stochastic network training I used around 2500 iterations\n",
    "\n",
    "    returns history of MSE and loss\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    # scaler = amp.GradScaler()\n",
    "    \n",
    "    # Здесь нам не надо running_loss и running_MSE, потому что подаем сразу весь датасета в типе non-stochastic GP\n",
    "\n",
    "    # Здесь реально обучаются параметры GPR, поскольку некоторая параметрическая часть у GPR все-таки присутствует\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train_X)\n",
    "\n",
    "        loss = loss_obj(output, train_Y)\n",
    "        loss.backward()\n",
    "\n",
    "        predictions = likelihood(model(train_X))\n",
    "        mean = predictions.mean\n",
    "        lower, upper = predictions.confidence_region()\n",
    "\n",
    "        # train_MSE = F.mse_loss(input=mean, target=train_Y, reduction='mean').item()   оно неправильно вычисляется, потому что в режиме train, мы mean получаем не для распределения у предсказаний, а тот который выучиили по трейну,\n",
    "        # Короче говоря в режиме train мы не \\mu* для объектов при предсказания получаем, а \\mu, которое получаем из трейн датасета\n",
    "\n",
    "        if i % print_step == 0:\n",
    "            print(f'Iter: {i + 1}, train_MSE = TODO, train_loss = {loss}')\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # history['MSE'].append(train_MSE)\n",
    "        history['loss'].append(loss.item())\n",
    "\n",
    "        if scheduler:\n",
    "            # Так как здесь обучение не по мини-батчам, то каждую итерацию обновление\n",
    "            scheduler.step()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно еще в процессе обучения параметров периодически смотреть на качество на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_eval(likelihood, model, optimizer, loss_obj, val_X, val_Y, val_Y_pinv_As, val_Y_3D):\n",
    "    '''\n",
    "    \n",
    "    One go dataset evaluation function\n",
    "\n",
    "    '''\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(val_X)\n",
    "        # loss = loss_obj(output, val_Y)\n",
    "\n",
    "    predictions = likelihood(model(val_X))\n",
    "\n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "\n",
    "    mean_3D = torch.bmm(val_Y_pinv_As, torch.unsqueeze(mean.to(torch.float), 2)).to(torch.device(\"cpu\"))    # используются для вычисления MSE метрики уже на 3D векторах силы\n",
    "    mean_3D = torch.squeeze(mean_3D, -1)\n",
    "\n",
    "    val_MSE = F.mse_loss(input=mean, target=val_Y, reduction='sum').item() / mean.size(0)\n",
    "    val_MSE_for_3D = F.mse_loss(input=mean_3D, target=val_Y_3D, reduction='sum').item() / mean_3D.size(0)\n",
    "\n",
    "    print(f'val_MSE = {val_MSE}, val_MSE_for_3D = {val_MSE_for_3D}')\n",
    "\n",
    "    return mean, mean_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    '''\n",
    "\n",
    "    Класс одиночной нейронной сети\n",
    "\n",
    "    '''\n",
    "    def __init__(self, extracted_size=CFG.K * CFG.K):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.FC = nn.Sequential(\n",
    "        #     nn.Linear(CFG.K * CFG.K, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 512),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.Linear(512, 256),\n",
    "\n",
    "        #     nn.Linear(256, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.Linear(128, extracted_size)\n",
    "        # )\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(CFG.K * CFG.K, 128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, extracted_size),\n",
    "        )\n",
    "\n",
    "        # self.FC = nn.Linear(flattened_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=CFG.output_size)\n",
    "feat_extractor = FeatureExtractor(extracted_size=32)\n",
    "\n",
    "model = IndependentOutputsMultitaskGPModel(\n",
    "    train_X,\n",
    "    train_Y,\n",
    "    likelihood,\n",
    "    # feature_extractor=feat_extractor\n",
    "    )\n",
    "\n",
    "if likelihood.num_tasks != model.output_size:\n",
    "    raise Exception('Different output dimensions for model and likelihood')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=0)\n",
    "\n",
    "NLL_loss = MinusLogLikelihoodLoss(likelihood=likelihood, model=model)\n",
    "MSE_loss = GPRMSELoss(likelihood=likelihood)\n",
    "\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Одно и то же значение для mean выводится в состоянии model.train(), потому что мы выбрали ConstMean и это типо и есть наше среднее, которое мы вычисляем по трейновому датасету**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, train_MSE = TODO, train_loss = 1.592382550239563\n",
      "Iter: 6, train_MSE = TODO, train_loss = 1.358294129371643\n",
      "Iter: 11, train_MSE = TODO, train_loss = 1.0678733587265015\n",
      "Iter: 16, train_MSE = TODO, train_loss = 0.7598523497581482\n",
      "Iter: 21, train_MSE = TODO, train_loss = 0.5129071474075317\n",
      "Iter: 26, train_MSE = TODO, train_loss = 0.28225454688072205\n",
      "Iter: 31, train_MSE = TODO, train_loss = 0.049493495374917984\n"
     ]
    }
   ],
   "source": [
    "train_history = GP_train(\n",
    "    likelihood=likelihood,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=None,\n",
    "    \n",
    "    loss_obj=NLL_loss,\n",
    "\n",
    "    training_iterations=35,\n",
    "\n",
    "    train_X=train_X,\n",
    "    train_Y=train_Y,\n",
    "\n",
    "    print_step=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "одинаковые аутпуты в eval будут, если у нас очень резко сетка становится широкой из низкоразмерных данных, если мы используем feature_extractor, то есть та же проблема, что была с сетками просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_MSE = 0.00193373979488237, val_MSE_for_3D = 0.00019534723079706086\n"
     ]
    }
   ],
   "source": [
    "mean, mean_3D = GP_eval(\n",
    "\n",
    "    likelihood=likelihood,\n",
    "    model=model,\n",
    "\n",
    "    optimizer=optimizer,\n",
    "    loss_obj=NLL_loss,\n",
    "\n",
    "    val_X=val_X,\n",
    "    val_Y=val_Y,\n",
    "\n",
    "    val_Y_pinv_As=val_Y_pinv_As,\n",
    "    val_Y_3D=val_Y_3D\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1196, -0.1886,  0.4450])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_Y_3D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Stochastic Variational GP Regression (обучение GPR по мини батчам):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пока мои выводы / результаты: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про сетки:\n",
    "    - Поскольку в датасете огромное количество сил очень маленькие - модель не в состоянии научиться определять болшьие силы, надо какой-то кастомный лосс придумывать, учитывающий это\n",
    "\n",
    "    - Пока по какой-то причине сетка просто выдает одинаковый аутпут на весь батч на большом количестве частиц (и со свертками и без, и при большом и при маленьком K)\n",
    "\n",
    "    - Для 2 частиц с K = 2 на одной сетке получилось val_MSE = 0.75\n",
    "\n",
    "    - Для 50 частиц с K = 25 вообще ничего не вышло, с K = 5 пока тоже\n",
    "\n",
    "Поэтому я пока отложу идею с 3 сетками и попробую покрутить GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про GP:\n",
    "    - на 50 частицах пока оно не учится...\n",
    "\n",
    "    - на 2 частицах результат получше, чем у сетки, но что-то мне подсказывает, что MSE довольно плохая метрика в нашей ситуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler=None):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum').item()\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_MSE = running_MSE / processed_data\n",
    "    \n",
    "    return train_loss, train_MSE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8b603c973ef7f83aae64b632e2e67529bc0c014d258c607b969039a8c89a028"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
