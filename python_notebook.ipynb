{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Run on python 3.6</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations:\n",
    "\n",
    "- выборка - тензор из картинок, таргет - вектор силы\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы используют multi output GPR, настраивая гиперпараметры $\\sigma_{cov}$ и $\\sigma_{err}$ (можно однозначно их выразить через гиперпараметры из того же sklearn: $l$ и $\\sigma$)\n",
    "\n",
    "GPR - непараметрический метод, суть в том, что мы делаем предположение о виде матрицы корреляции признаков для известных данных.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моделирование в хотя бы немного более сложном случае буду писать на Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры:\n",
    "\n",
    "1)k: Количество элементов в массивах r_cut и p для каждого атома\n",
    "\n",
    "2)$r_{cut}(i)_j$, i=1..k, j=1..N: векторы r_cut для j атома тоже параметр\n",
    "\n",
    "3)$p_(i)_j$, i=1..k, j=1..N: векторы p для j атома тоже параметр\n",
    "\n",
    "4)N_neighbours for summation for IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В GPyTorch есть имплементация многоразмерного регрессора: https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/index.html#multi-output-vector-valued-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Пока что все размерности предполагаются в системе LJ, потому что пока пытаюсь это зафитить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходно пока в coords.csv и forces.csv находятся для 2 частиц данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from numba import jit, njit, vectorize\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.linalg import norm as norm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''\n",
    "    \n",
    "    Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.\n",
    "\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    '''\n",
    "\n",
    "    All hyperparameters are here\n",
    "\n",
    "    '''\n",
    "\n",
    "    N = 3     # число атомов\n",
    "    K = 2     # можно называть это разрешением...чем число больше, тем больше размеры матрицы для атомов, фактически это число элементов в наборах p и r_cut\n",
    "\n",
    "    L = L = 2 * N ** (1 / 3) # размер одной клетки при моделировании\n",
    "\n",
    "    if K >= 6:\n",
    "        p = (np.random.rand(K) + 0.1).copy()\n",
    "        r_cut = (np.random.rand(K) + 0.1).copy()\n",
    "    else:\n",
    "        p = np.arange(0.5, (K + 1) * 0.5, 0.5)\n",
    "        r_cut = np.arange(0.5, (K + 1) * 0.5, 0.5)\n",
    "\n",
    "    N_neig= N - 1 if N != 2 else 1\n",
    "\n",
    "    # train_bs = 8\n",
    "    # val_bs = 16\n",
    "    batch_size = 256\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    f_threshold = 10    # Если сила по какой-то координате превышает это значение, то строчка исключается, совсем маленьких по модулю сил быть не должно, если что при генерации просто r_cut поменьше надо делать\n",
    "    coord_threshold = 2 * L     # Если вдруг очень большие расстояния, то надо выкидывать\n",
    "    #\n",
    "    output_size = 3     # Размерность аутпута модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется два .csv файла:\n",
    "\n",
    "1)\n",
    "| Id(time) | 1_x | 1_y | 1_z | ... | N_z |\n",
    "|------|-----|-----|-----|-----|-----|\n",
    "|      |     |     |     |     |     |\n",
    "|      |     |     |     |     |     |\n",
    "2)\n",
    "| Id(time) | f_1_x | f_1_y | f_1_z | ... | f_N_z |\n",
    "|------|-----|-----|-----|-----|-----|\n",
    "|      |     |     |     |     |     |\n",
    "|      |     |     |     |     |     |\n",
    "\n",
    "Одна строчка отсюда превращается в N матриц (на каждый атом) с N векторами сил\n",
    "\n",
    "В идеале сделать БДху из двух сущностей: сила и координата, где полями будут их проекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_coords(coords_file_path = None, forces_file_path = None):\n",
    "    '''\n",
    "    just makes df from .csvs with coords and forces\n",
    "    '''\n",
    "    coords = pd.read_csv(coords_file_path)\n",
    "\n",
    "    forces = pd.read_csv(forces_file_path)\n",
    "\n",
    "    if CFG.N != int(coords.columns[-1][:-1]) + 1:\n",
    "        raise Exception('Constant N is not equal to amount of particles in .csv')\n",
    "\n",
    "    return pd.merge(left=coords, right=forces, on='t').drop('t', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 индекс - 1 отн 2\n",
    "\n",
    "$$\n",
    "\\vec{r_1} = \\vec{r_2} + \\vec{r}_{12}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{r}_{12} = \\vec{r_1} - \\vec{r}_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_positions(row, atom_number):\n",
    "    '''\n",
    "    This function processes one row of csv into something that we can work with\n",
    "\n",
    "    Returns np.array matrix that consists of relative positions vectors for passed atom_number to every other atom\n",
    "    and then we can chose only closest N_neighbours in the next functions\n",
    "    \n",
    "    row: df.iloc[row] - typeof(row): pd.Series\n",
    "    \n",
    "    returns: Rel_matrix, f_vec\n",
    "    '''\n",
    "\n",
    "    s_coord = pd.Series(dtype=float)\n",
    "    other_atom_numbers = [i for i in range(CFG.N) if i != atom_number]\n",
    "\n",
    "    for other_numb in other_atom_numbers:\n",
    "        index = str(atom_number) + str(other_numb)\n",
    "        for axis in ['x', 'y', 'z']:\n",
    "            s_coord[index + axis] = row[str(atom_number) + axis] - row[str(other_numb) + axis]\n",
    "\n",
    "    # we need force vector only for atom_number:\n",
    "    force_vec = []\n",
    "    for f_axis in ['f_x', 'f_y', 'f_z']:\n",
    "        force_vec.append(row[str(atom_number) + f_axis])\n",
    "\n",
    "    Rel_matrix = []\n",
    "    cur_vector = []\n",
    "\n",
    "    for (i, elem) in enumerate(s_coord.values):\n",
    "        if i % 3 == 0 and i != 0:\n",
    "            Rel_matrix.append(cur_vector)\n",
    "            cur_vector = []\n",
    "\n",
    "        cur_vector.append(elem)\n",
    "    Rel_matrix.append(cur_vector)\n",
    "\n",
    "    return np.array(Rel_matrix), np.array(force_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def make_one_vec_transformed(vec, vec_norm, r_cut_i, p_i):\n",
    "    '''\n",
    "    vec: np.array - normalized vector\n",
    "    norm: its norm\n",
    "    r_cut_i: i-th component of\n",
    "    '''\n",
    "    return vec * np.exp(\n",
    "        -np.power((vec_norm / r_cut_i), p_i)\n",
    "        )\n",
    "\n",
    "make_matrix_transformed = np.vectorize(make_one_vec_transformed)\n",
    "\n",
    "def create_V_i(i, normalized_m, norms, r_cut=CFG.r_cut, p=CFG.p):\n",
    "    '''\n",
    "    normalized_m: matrix of relative distances, where rows - normalized vectors\n",
    "    i: i-th component of r_cut and p, i in range 1..K (or in 0..K-1 in code)\n",
    "    '''\n",
    "    transf_vecs = make_matrix_transformed(normalized_m, norms[:, np.newaxis], r_cut[i], p[i])\n",
    "\n",
    "    return np.sum(transf_vecs, axis=0)\n",
    "\n",
    "# @njit(parallel=True)\n",
    "def create_V(normalized_m, norms, K=CFG.K):\n",
    "    '''\n",
    "    creates V\n",
    "    '''\n",
    "    V = []\n",
    "    for i in range(K):\n",
    "        V.append(\n",
    "            create_V_i(i, normalized_m, norms)\n",
    "        )\n",
    "\n",
    "    return np.stack(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit(\n",
    "#     # parallel=True,\n",
    "#     # fastmath=True\n",
    "#     )\n",
    "def _calculate_matrix_for_atom(relative_distances, r_cut=CFG.r_cut, p=CFG.p, N_neig=CFG.N_neig, K=CFG.K):\n",
    "    '''\n",
    "\n",
    "    relative_distances: np.array matrix of relative distance vectors\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Only closest N_neig are counting:\n",
    "    indexlist = np.argsort(norm(relative_distances, axis=1))\n",
    "\n",
    "    relative_distances = relative_distances[indexlist[len(relative_distances) - N_neig:]]\n",
    "\n",
    "    norms = norm(relative_distances, axis=-1)\n",
    "\n",
    "    normalized_rel_distances = relative_distances / norms[:, np.newaxis]\n",
    "\n",
    "    V = create_V(normalized_rel_distances, norms)\n",
    "\n",
    "    if np.inf in V / norm(V, axis=-1)[:, np.newaxis] or np.nan in V / norm(V, axis=-1)[:, np.newaxis]:\n",
    "        print(f'V:\\n {V}\\n norms:\\n {norm(V, axis=-1)[:, np.newaxis]}\\n normed_V:\\n {V / norm(V, axis=-1)[:, np.newaxis]}')\n",
    "        print(f'ABOUT RELATIVE DISTANCES:\\n rel_dists:\\n {relative_distances}\\n norms:\\n{norms}\\n normalized_rel_dists:\\n {normalized_rel_distances}')\n",
    "\n",
    "    A = V / norm(V, axis=-1)[:, np.newaxis]\n",
    "\n",
    "    X = V @ A.T\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_for_atom(row = None, atom_number = None, N_neig=CFG.N_neig):\n",
    "    '''\n",
    "\n",
    "    This function will create X matrix for passed atom with\n",
    "    arrays of r_cut and p of length k\n",
    "\n",
    "    It is a wrapper for _get_relative_positions and _calculate_matrix_for_atom, so I can speed up matrix calculations\n",
    "    with numba for _calculate_matrix_for_atom\n",
    "\n",
    "    atom_number: a number of atom that we are passing\n",
    "    row: one row from df_with_coords, i.e. df.iloc[index_of_row]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # creating row of relative coordinates for concrete atom:\n",
    "    relative_distances, f_vec = _get_relative_positions(row=row, atom_number=atom_number)\n",
    "    X = _calculate_matrix_for_atom(relative_distances=relative_distances, N_neig=N_neig)\n",
    "    \n",
    "    return X, f_vec\n",
    "\n",
    "# %timeit get_matrix_for_atom(row=df.iloc[0], atom_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.31019351, 0.31017855],\n",
       "        [0.41595755, 0.41597761]]),\n",
       " array([0.37608813, 1.66607245, 2.64930888]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_with_coords('coords3.csv', 'forces3.csv')\n",
    "row = df.iloc[17000]\n",
    "\n",
    "get_matrix_for_atom(row, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**У нас будет train и val выборки, все-таки выборку, для который известен таргет принято называть validation, на которой мы качество оцениваем, а test это все-таки выборка, для который неизвестны таргеты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df: pd.DataFrame, f_threshold = CFG.f_threshold, coord_threshold=CFG.coord_threshold):\n",
    "    '''\n",
    "\n",
    "    Убирает строчки с аномально большими силами из df\n",
    "\n",
    "    '''\n",
    "\n",
    "    indexes_for_deletion = set()\n",
    "\n",
    "    for numb in range(CFG.N):\n",
    "        for coord in ['f_x', 'f_y', 'f_z']:\n",
    "\n",
    "            indexes_for_deletion = indexes_for_deletion.union(\n",
    "                set(df[abs(df[str(numb) + coord]) > f_threshold].index)\n",
    "            )\n",
    "\n",
    "        for coord in ['x', 'y', 'z']:\n",
    "            indexes_for_deletion = indexes_for_deletion.union(\n",
    "                set(df[abs(df[str(numb) + coord]) > coord_threshold].index)\n",
    "            )\n",
    "\n",
    "    return df.drop(list(indexes_for_deletion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(coords_file_path = 'coords.csv', forces_file_path = 'forces.csv', step=1, transform=transforms.ToTensor(), length=None,\n",
    "    f_threshold=CFG.f_threshold, coord_threshold=CFG.coord_threshold):\n",
    "    '''\n",
    "\n",
    "    Примитивная версия датасета, просто все будет хранить в одном тензоре...\n",
    "\n",
    "    Эта функция - wrapper на все выше написанные функции, она по переданным путям к .csv\n",
    "    возвращает тензор из матриц для каждого атома в каждой строчке и тензор из векторов сил\n",
    "\n",
    "\n",
    "    ИНогда есть смысл делать побольше шаг между соседними строчками, поскольку если есть почти одинаковые матрицы, то\n",
    "    это по-сути линейная зависимость и модель тогда надо сильнее регулизировать\n",
    "\n",
    "    transform: преобразование к X части датасета, в основном для нормализации нужно\n",
    "    step: через сколько строчек шагать при чтении csv в датасет, чтобы уж совсем одинаковых не было\n",
    "\n",
    "    '''\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    df = create_df_with_coords(coords_file_path=coords_file_path, forces_file_path=forces_file_path)\n",
    "    if length:\n",
    "        df = df.loc[range(length)]\n",
    "\n",
    "    # Сюда будет вставлена чистка df от больших сил\n",
    "    df = clean_df(df, f_threshold=f_threshold, coord_threshold=coord_threshold)\n",
    "\n",
    "    row_indexes = [i for i in range(0, len(df.index), step)]\n",
    "\n",
    "    for atom_number in range(CFG.N):\n",
    "        for index in tqdm(row_indexes, desc=f'Progress for atom {atom_number}'):\n",
    "            row = df.iloc[index]\n",
    "            x, f = get_matrix_for_atom(row=row, atom_number=atom_number)\n",
    "\n",
    "            if transform:\n",
    "                x = transform(x)\n",
    "            else:\n",
    "                x = transforms.ToTensor()(x)\n",
    "            x = x.to(torch.float)\n",
    "\n",
    "            dataset.append(\n",
    "                (x, torch.tensor(f, dtype=torch.float))\n",
    "                )\n",
    "            \n",
    "            # В дальнейшем для других моделей может иметь смысл хранить и возвращать тут (x, f, A), где A - соответствующая матрица для X\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Когда только начинаю работать с датасетом надо один раз на трейне посчитать std и mean, чтобы нормализовать можно было\n",
    "\n",
    "mean = 0.24053698778152466\n",
    "std = 0.07822638750076294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все-таки у нас тут не картинки будут, поэтому я попробую сначала даже без нормализации, нормализовать надо 1 канал, если в терминах картинки рассуждать\n",
    "\n",
    "transform = transforms.Compose([                                    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress for atom 0: 100%|██████████| 1210/1210 [00:03<00:00, 392.36it/s]\n",
      "Progress for atom 1: 100%|██████████| 1210/1210 [00:03<00:00, 396.65it/s]\n",
      "Progress for atom 2: 100%|██████████| 1210/1210 [00:03<00:00, 383.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset = create_tensor_dataset('coords3.csv', 'forces3.csv', step=70)\n",
    "\n",
    "# Uncomment, when calculated and changed mean and std:\n",
    "\n",
    "dataset = create_tensor_dataset('coords3.csv', 'forces3.csv', step=70, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока никакие параметры особо не надо настраивать, поэтому и кросс валидацию не буду делать пока что, затем ее можно сделать, передавая в функцию create_dataloaders еще один параметр - фолд, на котором трейн, предварительно поделив на фолды датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если просто брать в качестве трейна другие строчки из одной генерации, то можно не отследить переобучения, стоит пробовать тестить на датасете, который отдельно сгенерирован с таким же числом частиц, который модель еще вообще не видела"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 2]), tensor([[[-0.4184, -0.4746],\n",
       "          [ 0.1679,  0.2380]]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.33, random_state=42)\n",
    "\n",
    "train_data[30][0].size(), train_data[400][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Код для выяснения mean и std у трейновой выборки и для проверки уже после нормализации: (по ненормализованному датасету делается)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = -1.1293511903431863e-07, std = 1.0\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std_for_train_X(train_data):\n",
    "    train_X = torch.cat([row[0] for row in train_data])\n",
    "\n",
    "    print(\n",
    "        f'mean = {torch.mean(train_X)}, std = {torch.std(train_X)}'\n",
    "    )\n",
    "\n",
    "get_mean_and_std_for_train_X(train_data=train_data) # тупо проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Когда молекул уже будет много как хранить данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта клетка нужна будет, когда молекул будет много (N > 100, K порядка 100)\n",
    "\n",
    "def create_df_with_paths(df_coords: pd.DataFrame, first_folder = 'Atom_matrices'):\n",
    "    '''\n",
    "\n",
    "    Пока эта функция не нужна, но в будущем за счет нее как раз будет работать PathBasedDataset\n",
    "\n",
    "    gets df, returns df with paths to torch matrices for each atom for different times,\n",
    "    basically this function will call get_matrix_for_atom a lot of times\n",
    "\n",
    "    output: pd.DataFrame that orignated from this:\n",
    "    \n",
    "    | Index | 1_atom_X_path                     | ... | N_atom_X_path                     |\n",
    "    |-------|-----------------------------------|-----|-----------------------------------|\n",
    "    | 1     | ./atom_matrices/index1/atom1.tb   |     | ./atom_matrices/index1/atomN.tb   |\n",
    "    | ...   |                                   |     |                                   |\n",
    "    | 30k   | ./atom_matrices/index30k/atom1.tb |     | ./atom_matrices/index30k/atomN.tb |\n",
    "    \n",
    "    but eventually will look like this:\n",
    "\n",
    "    | Index   | atom_X_path                       |\n",
    "    |---------|-----------------------------------|\n",
    "    | 1       | ./atom_matrices/index1/atom1.tb   |\n",
    "    | ...     | ...                               |\n",
    "    | 30k * N | ./atom_matrices/index30k/atomN.tb |\n",
    "\n",
    "    '''\n",
    "    row_numbers = df_coords.index\n",
    "\n",
    "    df_paths = pd.DataFrame(\n",
    "        {\n",
    "            'path': []\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pass\n",
    "\n",
    "class PathBasedDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "\n",
    "    Это будет класс датасета из торча для большого числа молекул, если молекул будет очень много, то надо будет уже хранить все матрицы X не в оперативной памяти\n",
    "\n",
    "    При создании экземпляра будет передаваться pd.Dataframe, который\n",
    "    состоит из трех колонок - проекций вектора силы и еще одной колонки - путь к файлу, где лежит как-то заэнкоженная\n",
    "    матрица для данного атома, и так для каждого атома (я проверил, что запись и чтение при помощи torch.save и torch.load для тензоров очень быстрое)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, df, transforms=None, mode='train'):\n",
    "        self.df = df    # it will be dataframe with coordinates and forces of all atoms\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = 1   # it will be a matrix KxK for each atom\n",
    "        y = 1   # it will be a force vector with shape: (3)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, train_bs=CFG.batch_size, val_bs=CFG.batch_size, fold=None):\n",
    "    '''\n",
    "\n",
    "    Returns train_loader, val_loader\n",
    "\n",
    "    fold: will be used in cross validation, when I will implement it\n",
    "\n",
    "    '''\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=val_bs, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_dataloaders(train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].size()  # [batch_size, Channels, Height, Width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я попробую оба варианта:\n",
    "1) Многомерный аутпут\n",
    "2) Для каждой компоненты свой одномерный аутпут\n",
    "\n",
    "надо помнить, что сначала на двух частицах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)Многомерный аутпут:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще постоянный множитель - это не особо важно, но просто при оценке качества модели возникнут определенные трудности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultuOutputMSELoss(nn.MSELoss):\n",
    "    '''\n",
    "\n",
    "    Custom loss that calculates average over batch loss for multidim MSE - sum of MSE for components\n",
    "\n",
    "    Example:\n",
    "    |\n",
    "    |    Loss = MultuOutputMSELoss()\n",
    "    |\n",
    "    |    a = torch.ones((8, 3))      # it is batch of 8 vectors of size 3\n",
    "    |    b = torch.zeros((8, 3))\n",
    "    |\n",
    "    |    Loss(a, b, batch_size=8) -> 3\n",
    "\n",
    "    '''\n",
    "\n",
    "    def forward(self, input, target, batch_size=CFG.batch_size):\n",
    "        '''\n",
    "        оно при reduction='mean' делит на произведение всех размерностей\n",
    "        '''\n",
    "        # при очень большом размере батча последние батчи будут например размера 128 вместо 256, поэтому просто умножать на батч сайз неправильно, могут быть другого размера\n",
    "\n",
    "        return F.mse_loss(input, target, reduction='sum') / input.size(0)   # или эквивалентно делать reduction='mean' и умножать на input.size()[-1] - length of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flattener(torch.nn.Module):\n",
    "    '''\n",
    "\n",
    "    Module that flattens the input\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()    \n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNet(nn.Module):\n",
    "    '''\n",
    "\n",
    "    Класс одиночной нейронной сети\n",
    "\n",
    "    '''\n",
    "    def __init__(self, output_size, convolution=None, activation=nn.ReLU(), flattened_size=CFG.K * CFG.K):\n",
    "        '''\n",
    "        \n",
    "        FC_type: тип полносвязных слоев: 'regular' / 'simple\n",
    "\n",
    "        convolution: сверточная часть сети\n",
    "\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = flattener()\n",
    "\n",
    "        if convolution:\n",
    "            self.conv_layers = convolution\n",
    "\n",
    "        # self.FC = nn.Sequential(\n",
    "        #     nn.Linear(flattened_size, 1024),\n",
    "        #     activation,\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "\n",
    "        #     nn.Linear(1024, 512),\n",
    "        #     activation,\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.Linear(512, 256),\n",
    "\n",
    "        #     nn.Linear(256, 128),\n",
    "        #     activation,\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.Linear(128, output_size)\n",
    "        # )\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x - is batch of matrices KxK\n",
    "\n",
    "        # Здесь происходят какие-то там свертки, пуллинги и тп..\n",
    "\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики буду использовать сумму MSE по компонентам, лоссы попробую разные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler=None):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)    # при очень большом размере батча последние два батча будут например размера 128 вместо 256, поэтому просто умножать на батч сайз неправильно, могут быть другого размера\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum').item()\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = running_loss / processed_data\n",
    "    train_MSE = running_MSE / processed_data\n",
    "    \n",
    "    return train_loss, train_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    '''\n",
    "\n",
    "    Одна эпоха по val выборке\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # print(f' outputs:\\n{outputs}, \\n labels: \\n {labels}')\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum')\n",
    "        processed_size += inputs.size(0)\n",
    "\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_MSE = running_MSE.double().item() / processed_size\n",
    "    \n",
    "    return val_loss, val_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optimizer, scheduler, epochs, scaler=None, criterion=MultuOutputMSELoss()):\n",
    "    '''\n",
    "\n",
    "    Полный цикл обучения\n",
    "    \n",
    "    '''\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss {v_loss:0.4f} train_MSE {t_mse:0.4f} val_MSE {v_mse:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_MSE = fit_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "            val_loss, val_MSE = eval_epoch(model, val_loader, criterion)\n",
    "            if epoch != 0:\n",
    "                if history[-1][-1] < val_MSE:\n",
    "                    torch.save(model.state_dict(), './model.pth')     # сохраняем модель напрямую в гугл диск \n",
    "            \n",
    "            history.append((train_loss, train_MSE, val_loss, val_MSE))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss, v_loss=val_loss, t_mse=train_MSE, v_mse=val_MSE))\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "__conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(num_features=3),\n",
    "\n",
    "            # nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3),\n",
    "            # activation,\n",
    "            # nn.MaxPool2d(kernel_size=3),\n",
    "            # nn.BatchNorm2d(num_features=8)\n",
    "\n",
    "            flattener()\n",
    ")\n",
    "\n",
    "# Код для проверки длины конкатенированного вектора на вход в FC:\n",
    "\n",
    "# t = next(iter(train_loader))\n",
    "# a = conv_layers(t[0])\n",
    "# a.size()\n",
    "# a.view(a.size(0), -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleNet(\n",
    "    output_size=CFG.output_size,\n",
    "    # activation=nn.Tanh(),\n",
    "    convolution=None,\n",
    "    ).to(CFG.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=4e-3, betas=(0.9, 0.999), weight_decay=0.1)\n",
    "\n",
    "# scheduler.step нужно первый раз делать обязательно после optimizer.step, потому что иначе мы просто пропустим первый шаг scheduler\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleNet(\n",
       "  (conv_layers): flattener()\n",
       "  (FC): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  25%|██▌       | 5/20 [00:00<00:00, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 001 train_loss: 4.0833 val_loss 4.0137 train_MSE 4.0833 val_MSE 4.0137\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 002 train_loss: 3.7488 val_loss 4.0116 train_MSE 3.7488 val_MSE 4.0116\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 003 train_loss: 3.6930 val_loss 4.0072 train_MSE 3.6930 val_MSE 4.0072\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 004 train_loss: 3.7274 val_loss 3.9968 train_MSE 3.7274 val_MSE 3.9968\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 005 train_loss: 3.7324 val_loss 4.0639 train_MSE 3.7324 val_MSE 4.0639\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  55%|█████▌    | 11/20 [00:00<00:00, 29.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 006 train_loss: 3.7111 val_loss 4.0541 train_MSE 3.7111 val_MSE 4.0541\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 007 train_loss: 3.6905 val_loss 4.0157 train_MSE 3.6905 val_MSE 4.0157\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 008 train_loss: 3.6561 val_loss 4.0542 train_MSE 3.6561 val_MSE 4.0542\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 009 train_loss: 3.6662 val_loss 4.0356 train_MSE 3.6662 val_MSE 4.0356\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 010 train_loss: 3.6674 val_loss 4.0433 train_MSE 3.6674 val_MSE 4.0433\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 011 train_loss: 3.6520 val_loss 4.0200 train_MSE 3.6520 val_MSE 4.0200\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  90%|█████████ | 18/20 [00:00<00:00, 31.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 012 train_loss: 3.6393 val_loss 4.0196 train_MSE 3.6393 val_MSE 4.0196\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 013 train_loss: 3.6399 val_loss 4.0220 train_MSE 3.6399 val_MSE 4.0220\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 014 train_loss: 3.6383 val_loss 4.0339 train_MSE 3.6383 val_MSE 4.0339\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 015 train_loss: 3.6397 val_loss 4.0343 train_MSE 3.6397 val_MSE 4.0343\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 016 train_loss: 3.6354 val_loss 4.0293 train_MSE 3.6354 val_MSE 4.0293\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 017 train_loss: 3.6354 val_loss 4.0310 train_MSE 3.6354 val_MSE 4.0310\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 018 train_loss: 3.6338 val_loss 4.0297 train_MSE 3.6338 val_MSE 4.0297\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 20/20 [00:00<00:00, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 019 train_loss: 3.6339 val_loss 4.0330 train_MSE 3.6339 val_MSE 4.0330\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([256, 1, 2, 2]) torch.Size([256, 3])\n",
      "torch.Size([128, 1, 2, 2]) torch.Size([128, 3])\n",
      "\n",
      "Epoch 020 train_loss: 3.6372 val_loss 4.0397 train_MSE 3.6372 val_MSE 4.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    train_loader=train_loader, val_loader=val_loader, model=model, optimizer=optimizer,\n",
    "    scheduler=exp_scheduler, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history, figsize=(40, 15)):\n",
    "    '''\n",
    "\n",
    "    history: [(train_loss, train_MSE, val_loss, val_MSE), ...]\n",
    "\n",
    "    '''\n",
    "\n",
    "    # writer = SummaryWriter()\n",
    "    \n",
    "    figure = plt.figure(figsize=figsize)\n",
    "\n",
    "    train_loss = [tup[0] for tup in history]\n",
    "    train_MSE = [tup[1] for tup in history]\n",
    "    val_loss = [tup[2] for tup in history]\n",
    "    val_MSE = [tup[3] for tup in history]\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(range(1, len(history) + 1), train_loss, label='train_loss')\n",
    "    plt.plot(range(1, len(history) + 1), val_loss, label='val_loss')\n",
    "    \n",
    "    plt.title('Losses', fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)     \n",
    "    plt.xticks(np.arange(1, len(history) + 1, 1))\n",
    "    # plt.yticks(np.arange(1, len(history) + 1, 1))\n",
    "    plt.legend(loc='best')\n",
    "    #\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(range(1, len(history) + 1), train_MSE, label='train_MSE')\n",
    "    plt.plot(range(1, len(history) + 1), val_MSE, label='val_MSE')\n",
    "    \n",
    "    plt.title('Metrics', fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('loss', fontsize=14)     \n",
    "    plt.xticks(np.arange(1, len(history) + 1, 1))\n",
    "    # plt.yticks(np.arange(1, len(history) + 1, 1))\n",
    "    plt.legend(loc='best', fontsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbcad5e2828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Output_size сеток с одномерным аутпутом (предполагаем независимость всех компонент силы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто обучаю набор сеток на задачу регрессии, в качестве метрики для каждой сетки буду использовать MSE, а итоговая метрика - сумма MSE для каждой сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Просто делаю массив из экземпляров сеток, optim-ов, loss-ов и потом циклом по ним делаю ровно тот же самый вызов history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всем сеткам делаю абсолютно одинаковые гиперпараметры\n",
    "\n",
    "models = [SingleNet(output_size=1) for _ in range(CFG.output_size)]\n",
    "\n",
    "lr = 4e-3\n",
    "betas=(0.9, 0.999)\n",
    "weight_decay=0.1\n",
    "\n",
    "optims = [optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay) for model in models]\n",
    "\n",
    "step_size = 5\n",
    "gamma = 0.1\n",
    "\n",
    "exp_schedulers = [lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) for optimizer in optims]\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое главное при обучении этих моделей - то что у model[ i ] - таргет - это число force[ i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    '''\n",
    "    \n",
    "    Возвращает словарь из history для всех моделей: {1: history, 2: history, ...}\n",
    "\n",
    "    '''\n",
    "\n",
    "    histories = defaultdict(list)\n",
    "\n",
    "    # Надо менять немного цикл обучения, чтобы таргетом для i сетки была i-ая компонента вектора силы\n",
    "\n",
    "    # for i in range(CFG.output_size):\n",
    "    #     histories[str(i)] = train(\n",
    "    #         train_loader=train_loader,\n",
    "    #         val_loader=val_loader,\n",
    "    #         model=model,\n",
    "    #         optimizer=optimizer,\n",
    "    #         scheduler=exp_scheduler,\n",
    "    #         criterion=nn.MSELoss(),\n",
    "    #         epochs=10\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) GPR модель \n",
    "    - (потом можно сюда навалить и сетку в качестве ядра и вообще deep GP юзать, плюс еще feature extractor в виде сверток юзать сначала, если очень большая матрица, но сначала надо обычный сделать)\n",
    "\n",
    "## 3.1) Не стохастический подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html - как обучать модели в gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.gpytorch.ai/en/v1.3.1/examples/04_Variational_and_Approximate_GPs/SVGP_Regression_CUDA.html - как обучать GP по мини батчам, когда данных слишком много"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У авторов $C_{mn}$ - это матрица ковариации по всему датасету, а $d_{mn}$ - некоторое введенное расстояние между матрицами, чтобы мы могли использовать экспоненциальное ядро, короче нам надо какое-то ядро, которое две матрицы, а не два числа принимает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Весьма убедительно считать расстояние между матрицами просто как l2 метрику между точками в NxN мерном пространстве"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короче надо GPR сделать, у которого точки - матрицы и прогнозируется векторная величина, то есть для матрицы $x_*$ из инпута мы должны получать: $\\mu_* = E[f(x_*)]$ - трехмерное мат ожидание для предсказания и $S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В предположении что компоненты силы независимы, можно использовать Batch Independent Multioutput GP, предсказывая [fx, fy, fz]\n",
    "\n",
    "- Если предсказывать k проекций на все V_i, то компоненты уже зависимые и надо это учитывать и использовать другую модель: MultitaskGPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лосс делаем -mll: минус логарифм правдоподобия: $-log[p(output Y | test X)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = torch.stack([elem[0] for elem in train_data])\n",
    "# train_Y = torch.stack([elem[1] for elem in train_data])\n",
    "\n",
    "# val_X = torch.stack([elem[0] for elem in val_data])\n",
    "# val_Y = torch.stack([elem[1] for elem in val_data])\n",
    "\n",
    "fl = flattener()\n",
    "train_X = fl(torch.stack([elem[0] for elem in train_data]))\n",
    "train_Y = fl(torch.stack([elem[1] for elem in train_data]))\n",
    "\n",
    "val_X = fl(torch.stack([elem[0] for elem in val_data]))\n",
    "val_Y = fl(torch.stack([elem[1] for elem in val_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Про свертки и когда они ожидаемо будут и не будут работать:**\n",
    "\n",
    "    - если мы используем обычный GP, то мы обязаны каждый шаг обучаться на всем train_X - так алгоритм работает, поэтому и сверточная сеть так же должна будет обучаться, по-сути с батч_сайз = дата_сайз, но оно так вычислительно неподъемно или просто не успеет за такое маленькое количество шагов обучиться\n",
    "\n",
    "    - Поэтому стоит использовать алгоритм Stochastic Variational GP Regression, который подразумевает совместимость с torch.DataLoader, когда данных будет очень много, там используется стохастический алгоритм, позволяющий на батче обновлять параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependentOutputsMultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    '''\n",
    "\n",
    "    Class for multi output GPregression with independent components of output,\n",
    "    formally we are training output_size GP models\n",
    "\n",
    "    feature_extractor: torch network that consists only of convolutions (fully convolutional net)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, train_x, train_y, likelihood, output_size=3, feature_extractor=None):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([output_size]))     # batch_shape позволяет нам для каждой модели отдельные параметры сделать\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([output_size])),\n",
    "        )\n",
    "\n",
    "        self.feature_extractor = flattener()\n",
    "        if feature_extractor:\n",
    "            self.feature_extractor = feature_extractor\n",
    "\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        convoluted_n_flattened_x = self.feature_extractor(x)   # flattening\n",
    "        convoluted_n_flattened_x = self.scale_to_bounds(convoluted_n_flattened_x)\n",
    "\n",
    "        mean_x = self.mean_module(convoluted_n_flattened_x)\n",
    "        covar_x = self.covar_module(convoluted_n_flattened_x)\n",
    "\n",
    "        # print(f'Сайз выпрямленного:  {convoluted_n_flattened_x.size()} \\n Сам выпрямленный: {convoluted_n_flattened_x}')\n",
    "\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal.from_batch_mvn(\n",
    "            gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinusLogLikelihoodLoss:\n",
    "    def __init__(self, likelihood, model):\n",
    "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    def __call__(self, model_output, true_target):\n",
    "        '''\n",
    "\n",
    "        model_output: what model(train_x) returns, mll uses likelihood by itself\n",
    "\n",
    "        returns -mll(output, target)\n",
    "\n",
    "        '''\n",
    "        return -self.mll(model_output, true_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_train(likelihood, model, optimizer, loss_obj, training_iterations: int, train_X, train_Y, print_step=1, scheduler=None):\n",
    "    '''\n",
    "\n",
    "    loss_obj should be an object of a class, which has __call__ method\n",
    "\n",
    "    to have a clear perspective: on a stochastic network training I used around 2500 iterations\n",
    "\n",
    "    returns history of MSE and loss\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    # scaler = amp.GradScaler()\n",
    "    \n",
    "    # Здесь нам не надо running_loss и running_MSE, потому что подаем сразу весь датасета в типе non-stochastic GP\n",
    "\n",
    "    # Здесь реально обучаются параметры GPR, поскольку некоторая параметрическая часть у GPR все-таки присутствует\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train_X)\n",
    "\n",
    "        loss = loss_obj(output, train_Y)\n",
    "        loss.backward()\n",
    "\n",
    "        predictions = likelihood(model(train_X))\n",
    "        mean = predictions.mean\n",
    "        lower, upper = predictions.confidence_region()\n",
    "\n",
    "        # train_MSE = F.mse_loss(input=mean, target=train_Y, reduction='mean').item()   оно неправильно вычисляется, потому что в режиме train, мы mean получаем не для распределения у предсказаний, а тот который выучиили по трейну,\n",
    "        # Короче говоря в режиме train мы не \\mu* для объектов при предсказания получаем, а \\mu, которое получаем из трейн датасета\n",
    "\n",
    "        if i % print_step == 0:\n",
    "            print(f'Iter: {i + 1}, train_MSE = TODO, train_loss = {loss}')\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # history['MSE'].append(train_MSE)\n",
    "        history['loss'].append(loss.item())\n",
    "\n",
    "        if scheduler:\n",
    "            # Так как здесь обучение не по мини-батчам, то каждую итерацию обновление\n",
    "            scheduler.step()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно еще в процессе обучения параметров периодически смотреть на качество на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_eval(likelihood, model, optimizer, loss_obj, val_X, val_Y):\n",
    "    '''\n",
    "    \n",
    "    One go dataset evaluation function\n",
    "\n",
    "    '''\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(val_X)\n",
    "        loss = loss_obj(output, val_Y)\n",
    "\n",
    "    predictions = likelihood(model(val_X))\n",
    "\n",
    "    mean = predictions.mean\n",
    "    print(mean)\n",
    "    lower, upper = predictions.confidence_region()\n",
    "\n",
    "    val_MSE = F.mse_loss(input=mean, target=val_Y, reduction='mean').item()\n",
    "\n",
    "    print(f'val_MSE = {val_MSE}, val_loss = {loss.item()}')\n",
    "\n",
    "    return mean, lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(LargeFeatureExtractor, self).__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(CFG.K * CFG.K, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))\n",
    "        self.add_module('relu2', torch.nn.ReLU())\n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
    "\n",
    "model = IndependentOutputsMultitaskGPModel(\n",
    "    train_X,\n",
    "    train_Y,\n",
    "    likelihood,\n",
    "    # feature_extractor=LargeFeatureExtractor()\n",
    "    )\n",
    "\n",
    "if likelihood.num_tasks != model.output_size:\n",
    "    raise Exception('Different output dimensions for model and likelihood')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=0.1)\n",
    "\n",
    "loss_obj = MinusLogLikelihoodLoss(likelihood=likelihood, model=model)\n",
    "\n",
    "exp_scheduler = lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Одно и то же значение для mean выводится в состоянии model.train(), потому что мы выбрали ConstMean и это типо и есть наше среднее, которое мы вычисляем по трейновому датасету**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, train_MSE = TODO, train_loss = 1.186328411102295\n",
      "Iter: 6, train_MSE = TODO, train_loss = 1.0464164018630981\n",
      "Iter: 11, train_MSE = TODO, train_loss = 0.9537036418914795\n",
      "Iter: 16, train_MSE = TODO, train_loss = 0.9310539960861206\n",
      "Iter: 21, train_MSE = TODO, train_loss = 0.9389874339103699\n",
      "Iter: 26, train_MSE = TODO, train_loss = 0.9425256848335266\n",
      "Iter: 31, train_MSE = TODO, train_loss = 0.9464433193206787\n"
     ]
    }
   ],
   "source": [
    "train_history = GP_train(\n",
    "    likelihood=likelihood,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=None,\n",
    "    loss_obj=loss_obj,\n",
    "\n",
    "    training_iterations=35,\n",
    "\n",
    "    train_X=train_X,\n",
    "    train_Y=train_Y,\n",
    "\n",
    "    print_step=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "одинаковые аутпуты в eval будут, если у нас очень резко сетка становится широкой из низкоразмерных данных, если мы используем feature_extractor, то есть та же проблема, что была с сетками просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.9993e-03, -2.5698e-03, -6.0732e-03],\n",
      "        [-5.9756e-02, -1.2247e-01, -2.1222e-02],\n",
      "        [ 1.4654e-03,  7.1156e-04,  1.0054e-03],\n",
      "        ...,\n",
      "        [-3.5368e-03, -1.1724e-03, -3.5406e-03],\n",
      "        [ 2.9278e-04, -2.6193e-05,  1.0932e-03],\n",
      "        [ 3.1863e-03,  1.2617e-03,  3.4143e-03]], grad_fn=<ViewBackward0>)\n",
      "val_MSE = 0.6409152746200562, val_loss = 1.1754387617111206\n"
     ]
    }
   ],
   "source": [
    "mean, lower, upper = GP_eval(\n",
    "    likelihood=likelihood,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_obj=loss_obj,\n",
    "    val_X=val_X,\n",
    "    val_Y=val_Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Stochastic Variational GP Regression (обучение GPR по мини батчам):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пока мои выводы / результаты: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про сетки:\n",
    "    - Поскольку в датасете огромное количество сил очень маленькие - модель не в состоянии научиться определять болшьие силы, надо какой-то кастомный лосс придумывать, учитывающий это\n",
    "\n",
    "    - Пока по какой-то причине сетка просто выдает одинаковый аутпут на весь батч на большом количестве частиц (и со свертками и без, и при большом и при маленьком K)\n",
    "\n",
    "    - Для 2 частиц с K = 2 на одной сетке получилось val_MSE = 0.75\n",
    "\n",
    "    - Для 50 частиц с K = 25 вообще ничего не вышло, с K = 5 пока тоже\n",
    "\n",
    "Поэтому я пока отложу идею с 3 сетками и попробую покрутить GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Про GP:\n",
    "    - на 50 частицах пока оно не учится...\n",
    "\n",
    "    - на 2 частицах результат получше, чем у сетки, но что-то мне подсказывает, что MSE довольно плохая метрика в нашей ситуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler, scaler=None):\n",
    "    '''\n",
    "\n",
    "    Функция обучения по всем батчам 1 раз (1 эпоха)\n",
    "\n",
    "    scaler: gradient scaler from torch.amp, попозже добавлю обучение с ним\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_MSE = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(CFG.device)\n",
    "        labels = labels.to(CFG.device)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_MSE += F.mse_loss(input=outputs, target=labels, reduction='sum').item()\n",
    "        processed_data += inputs.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_MSE = running_MSE / processed_data\n",
    "    \n",
    "    return train_loss, train_MSE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8b603c973ef7f83aae64b632e2e67529bc0c014d258c607b969039a8c89a028"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
