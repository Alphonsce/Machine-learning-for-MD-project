{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "\n",
    "from utility_funcs import *\n",
    "\n",
    "import dill\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, ConstantKernel, RBF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"gpr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNet(nn.Module):\n",
    "    '''\n",
    "\n",
    "    Класс одиночной нейронной сети\n",
    "\n",
    "    '''\n",
    "    def __init__(self, output_size, activation=nn.ReLU(), flattened_size=CFG.K * CFG.K):\n",
    "        '''\n",
    "        \n",
    "        FC_type: тип полносвязных слоев: 'regular' / 'simple\n",
    "\n",
    "        convolution: сверточная часть сети\n",
    "\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.FC = nn.Sequential(\n",
    "        #     # nn.BatchNorm1d(flattened_size),\n",
    "\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.Linear(128, 256),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 256),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 256),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            # nn.Linear(256, 256),\n",
    "            # activation,\n",
    "            # # nn.Dropout(0.3),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            activation,\n",
    "            # nn.Dropout(0.3),\n",
    "            # nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "\n",
    "        # self.FC = nn.Sequential(\n",
    "        #     nn.Linear(flattened_size, 64),\n",
    "        #     activation,\n",
    "\n",
    "        #     nn.Linear(64, output_size)\n",
    "        # )\n",
    "\n",
    "        # self.FC = nn.Linear(flattened_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x - is batch of matrices KxK\n",
    "\n",
    "        # Здесь происходят какие-то там свертки, пуллинги и тп..\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnModel:\n",
    "    def __init__(self, model):\n",
    "        '''\n",
    "        model - sklearn model\n",
    "        '''\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = f'./trained_models/{model_type}_{CFG.N}_movements_K{CFG.K}.pickle'\n",
    "model_vel_file_path = f'./trained_models/{model_type}_{CFG.N}_velocities_K{CFG.K}.pickle'\n",
    "\n",
    "# Сетка предсказания сжатые будет выдавать и их надо будет возвращать к обычному скейлу\n",
    "descaler_path = f'./trained_models/descaler_{CFG.N}_K{CFG.K}.pickle'\n",
    "descaler_vel_path = f'./trained_models/descaler_vel_{CFG.N}_K{CFG.K}.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_file_path, 'rb') as handle:\n",
    "    model = dill.load(handle)\n",
    "\n",
    "with open(model_vel_file_path, 'rb') as handle:\n",
    "    model_vel = dill.load(handle)\n",
    "\n",
    "if model_type == \"gpr\":\n",
    "    descaler = Descaler(1, 0)\n",
    "    descaler_vel = Descaler(1, 0)\n",
    "    model = SklearnModel(model)\n",
    "    model_vel = SklearnModel(model_vel)\n",
    "else:\n",
    "    with open(descaler_path, 'rb') as handle:\n",
    "        descaler = dill.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_row_to_state(coords_path, vels_path, row_number=0):\n",
    "    '''\n",
    "    This function will be mostly used to start integration and create header for csv to write into\n",
    "    '''\n",
    "\n",
    "    row_coords = np.array(pd.read_csv(\n",
    "        coords_path\n",
    "    ).iloc[row_number, :][1:]).reshape(CFG.N, 3)\n",
    "\n",
    "    row_vels = np.array(pd.read_csv(\n",
    "        vels_path\n",
    "    ).iloc[0, :][1:]).reshape(CFG.N, 3)\n",
    "    \n",
    "    state = {i: [row_coords[i], row_vels[i]] for i in range(CFG.N)}\n",
    "\n",
    "\n",
    "    return state\n",
    "\n",
    "state = csv_row_to_state(\n",
    "    f'./coords_and_movements/coords{CFG.N}.csv',\n",
    "    f'./coords_and_movements/velocities{CFG.N}.csv',\n",
    "\n",
    "    row_number=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_positions(state, atom_number):\n",
    "    '''\n",
    "    This function processes one row of csv into something that we can work with\n",
    "\n",
    "    Returns np.array matrix that consists of relative positions vectors for passed atom_number to every other atom\n",
    "    and then we can chose only closest N_neighbours in the next functions\n",
    "    \n",
    "    row: df.iloc[row] - typeof(row): pd.Series\n",
    "    \n",
    "    returns: Rel_matrix, f_vec\n",
    "    '''\n",
    "\n",
    "    other_atom_numbers = [i for i in range(CFG.N) if i != atom_number]\n",
    "    Rel_matrix = np.zeros([CFG.N - 1, 3])\n",
    "\n",
    "    for i, other_numb in enumerate(other_atom_numbers):\n",
    "        Rel_matrix[i] = state[atom_number][0] - state[other_numb][0]\n",
    "\n",
    "    # print('rel_dists: ', Rel_matrix)\n",
    "\n",
    "    return np.array(Rel_matrix)\n",
    "\n",
    "def create_V_i(i, normalized_m, norms, r_cut=CFG.r_cut, p=CFG.p):\n",
    "    '''\n",
    "    normalized_m: matrix of relative distances, where rows - normalized vectors\n",
    "    i: i-th component of r_cut and p, i in range 1..K (or in 0..K-1 in code)\n",
    "    '''\n",
    "    transf_vecs = make_matrix_transformed(normalized_m, norms[:, np.newaxis], r_cut[i], p[i])\n",
    "\n",
    "    return np.sum(transf_vecs, axis=0)\n",
    "\n",
    "# @njit(parallel=True)\n",
    "def create_V(normalized_m, norms, K=CFG.K):\n",
    "    '''\n",
    "    creates V\n",
    "    '''\n",
    "    V = []\n",
    "    for i in range(K):\n",
    "        V.append(\n",
    "            create_V_i(i, normalized_m, norms)\n",
    "        )\n",
    "\n",
    "    return np.stack(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit(\n",
    "#     parallel=True,\n",
    "#     fastmath=True\n",
    "#     )\n",
    "def _calculate_matrix_for_atom(relative_distances, r_cut=CFG.r_cut, p=CFG.p, N_neig=CFG.N_neig, K=CFG.K, use_orthogonal=False, use_A_t=True):\n",
    "    '''\n",
    "\n",
    "    relative_distances: np.array matrix of relative distance vectors\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Only closest N_neig are counting:\n",
    "    indexlist = np.argsort(norm(relative_distances, axis=1))\n",
    "\n",
    "    relative_distances = relative_distances[indexlist[len(relative_distances) - N_neig:]]\n",
    "\n",
    "    norms = norm(relative_distances, axis=-1)\n",
    "\n",
    "    normalized_rel_distances = relative_distances / norms[:, np.newaxis]\n",
    "\n",
    "    V = create_V(normalized_rel_distances, norms)\n",
    "\n",
    "    if use_orthogonal and CFG.K == 3:\n",
    "        diagonal_V_matr = [[0] * CFG.K for i in range(K)]\n",
    "        for i in range(K):\n",
    "            diagonal_V_matr[i][i] = V[i][i]\n",
    "        V = np.array(\n",
    "            diagonal_V_matr\n",
    "        )\n",
    "\n",
    "    A = V / norm(V, axis=-1)[:, np.newaxis]\n",
    "\n",
    "    if use_A_t:\n",
    "        X = V @ A.T\n",
    "    else:\n",
    "        X = V\n",
    "\n",
    "    return X, A\n",
    "\n",
    "def get_matrix_for_atom(state, atom_number, N_neig=CFG.N_neig, use_orthogonal=True, use_A_t=True):\n",
    "    '''\n",
    "\n",
    "    This function will create X matrix for passed atom with\n",
    "    arrays of r_cut and p of length k\n",
    "\n",
    "    It is a wrapper for _get_relative_positions and _calculate_matrix_for_atom, so I can speed up matrix calculations\n",
    "    with numba for _calculate_matrix_for_atom\n",
    "\n",
    "    atom_number: a number of atom that we are passing\n",
    "    row: one row from df_with_coords, i.e. df.iloc[index_of_row]\n",
    "\n",
    "    '''\n",
    "    # @njit\n",
    "    def get_pinv(A):\n",
    "        return np.linalg.pinv(A)\n",
    "\n",
    "    # creating row of relative coordinates for concrete atom:\n",
    "    relative_distances = _get_relative_positions(state=state, atom_number=atom_number)\n",
    "    X, A = _calculate_matrix_for_atom(relative_distances=relative_distances, N_neig=N_neig, use_orthogonal=use_orthogonal, use_A_t=use_A_t)\n",
    "\n",
    "    flat_X = np.concatenate([X.flatten(), state[atom_number][1]])\n",
    "    \n",
    "    return flat_X, get_pinv(A)\n",
    "\n",
    "# %timeit get_matrix_for_atom(row=df.iloc[0], atom_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-951-38259ada2ef6>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-951-38259ada2ef6>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "csv_naming = []\n",
    "for i in range(CFG.N):\n",
    "    csv_naming.extend([str(i) + \"x\", str(i) + \"y\", str(i) + \"z\"])\n",
    "result_csv = \"./integration_res/result_coords.csv\"\n",
    "\n",
    "\n",
    "def fill_csv(state, path):\n",
    "    '''\n",
    "    fills csv after current step\n",
    "    '''\n",
    "    for atom_numb in range(CFG.N):\n",
    "        pass\n",
    "\n",
    "def fill_xyz(state, path):\n",
    "    '''\n",
    "    fills xyz file after current step\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(X, pinv_A, model):\n",
    "    return pinv_A @ model(X.reshape(1, -1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(state, model):\n",
    "    '''\n",
    "    predicting on multiple rows is faster\n",
    "    '''\n",
    "    Xs = []\n",
    "    pinv_As = []\n",
    "    for atom_num in range(CFG.N):\n",
    "        X, pinv_A = get_matrix_for_atom(state=state, atom_number=atom_num)\n",
    "        Xs.append(X)\n",
    "        pinv_As.append(pinv_A)\n",
    "    Xs = np.array(Xs, dtype=np.float32)\n",
    "    pinv_As = np.array(pinv_As)\n",
    "    preds = model(Xs)\n",
    "\n",
    "    return [pinv_As[i] @ preds[i] for i in range(CFG.N)]\n",
    "\n",
    "# make_predictions(state, model=model)\n",
    "\n",
    "# make_predictions(state, model=model_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_step(state):\n",
    "    dses = make_predictions(state, model)\n",
    "    dvs = make_predictions(state, model_vel)\n",
    "    for atom_num in range(CFG.N):\n",
    "        state[atom_num][0] += dses[atom_num]\n",
    "        state[atom_num][1] += dvs[atom_num]\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([-0.08500186,  0.04863722,  0.03553856]),\n",
       "  array([-1.55676056, -0.37403802,  0.2729956 ])],\n",
       " 1: [array([ 1.36564848, -0.02256105, -0.04215596]),\n",
       "  array([-4.65428112,  2.24508663,  0.62201187])],\n",
       " 2: [array([-0.05339952,  1.37264916,  0.00597156]),\n",
       "  array([-1.58769599, -3.75978543,  0.09783248])]}"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_step(state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_cycle(state, number_of_steps, csv_path=None, xyz_path=None):\n",
    "    '''\n",
    "    state: starting state\n",
    "    '''\n",
    "    for step in range(number_of_steps):\n",
    "        fill_csv(step, csv_path)\n",
    "        fill_xyz(step, xyz_path)\n",
    "        state = make_step(state)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([-0.42024516, -0.12250679,  0.12140434]),\n",
       "  array([-0.54730273,  0.67520562,  1.94337576])],\n",
       " 1: [array([ 1.36126203, -0.02151821, -0.04165194]),\n",
       "  array([-5.47814555,  2.48833797,  0.66326832])],\n",
       " 2: [array([-0.05499572,  1.35640266,  0.04343953]),\n",
       "  array([-2.21367084, -4.66874242, -0.52754341])]}"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integration_cycle(state=state, number_of_steps=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_3_6_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b5cc6bf18c7103cb99324f044582e9ca68eda52a25f7227b20ca62cd3e32898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
